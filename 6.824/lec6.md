







前面已经提过，有关过半票决系统的一个特性就是，最多只有一个网络分区会有过半的服务器，所以我们不可能有两个分区可以同时完成操作。这里背后更微妙的点在于，如果你总是需要过半的服务器才能完成任何操作，同时你有一系列的操作需要完成，其中的每一个操作都需要过半的服务器来批准，例如选举Raft的Leader，那么每一个操作对应的过半服务器，必然至少包含一个服务器存在于上一个操作的过半服务器中。也就是说，任意两组过半服务器，至少有一个服务器是重叠的。实际上，相比其他特性，Raft更依赖这个特性来避免脑裂。例如，当一个Raft Leader竞选成功，那么这个Leader必然凑够了过半服务器的选票，而这组过半服务器中，必然与旧Leader的过半服务器有重叠。所以，新的Leader必然知道旧Leader使用的任期号（term number），因为新Leader的过半服务器必然与旧Leader的过半服务器有重叠，而旧Leader的过半服务器中的每一个必然都知道旧Leader的任期号。类似的，任何旧Leader提交的操作，必然存在于过半的Raft服务器中，而任何新Leader的过半服务器中，必然有至少一个服务器包含了旧Leader的所有操作。这是Raft能正确运行的一个重要因素。



这个问题非常关键，涉及 Raft 一致性的核心保证之一。我们拆解你的问题：

------

### ❓问题核心：

> **服务器包含了旧 Leader 的所有操作，这个服务器一定会被选做新 Leader 吗？**

**简短回答：**

> **❌ 不一定。**
>
> 但 **Raft 机制确保：新当选的 Leader 只能是包含“最新日志”的节点之一。**

------

## 🧠 更完整的解释

### ✅ 背景重述：

Raft 要求：

1. 每次选举，必须赢得 **过半数投票**。
2. 每个节点在投票时会比较 **候选者的日志是否“足够新”**。
3. 如果候选者的日志 **落后于当前节点**，则拒绝投票。

这就是所谓的 **“日志新旧规则（log up-to-date rule）”**：

> 一个节点只有在它还没有投票，**并且** 候选者的日志不落后于自己的情况下，才会投票给候选者。

------

### ✅ 因此，虽然 **日志最完整的节点** 不一定当选，但：

- 若某个节点的日志 **不包含旧 leader 的提交日志（entry）**，它就无法赢得多数；
- 所以，**能当选的新 leader，其日志一定“不会比旧 leader 的提交日志更老”**；
- 这就保证了：**提交日志一定会被保存在新 leader 的过半数节点中**。

------

### 📌 举个例子理解：

假设你有 5 个节点（A, B, C, D, E）：

- 当前 Leader 是 A，它已经提交了日志条目 `X`。
- 这些提交是通过多数（比如 A, B, C）完成的，所以 B 和 C 必然也有 `X`。
- 现在网络分区，A 失联，系统开始选举。

#### ❌ 如果一个没有 `X` 的节点（如 E）要成为 leader：

- 它要获得 3 张选票。
- 但 **B 和 C 不会给 E 投票**，因为它们会发现 E 的日志落后（没有 `X`）。
- 所以 E 拿不到过半选票，**选不上**。

------

### ✅ 最终确保了什么？

- 新 leader 的日志必须 **不落后于** 拥有已提交日志的节点；
- 所以，**已提交日志一定存在于新 leader 以及其选票支持者（多数）中**；
- 这使得 **日志不会被“覆盖”或“遗忘”**。

------

### ✅ 所以总结：

| 说法                                            | 是否正确 | 解释                                                     |
| ----------------------------------------------- | -------- | -------------------------------------------------------- |
| “包含旧 leader 所有操作的节点一定会当选 leader” | ❌ 不一定 | 虽然它有资格，但实际投票过程还取决于选举时机、网络状况等 |
| “新 leader 一定包含旧 leader 所有提交操作”      | ✅ 是的   | Raft 的日志一致性和选举机制保证了这一点                  |

------

### 📎 附加一句论文原话支持：

> *Raft ensures that if a log entry is committed in a given term, then that entry will be present in the logs of all future leaders.*

------

如你进一步想深入这部分机制（如 why Leader Completeness Property is essential for log consistency），我也可以继续展开讲解。是否继续？





当一个操作最终在Leader节点被提交之后，每个副本节点的Raft层会将相同的操作提交到本地的应用程序层。在本地的应用程序层，会将这个操作更新到自己的状态。所以，理想情况是，所有的副本都将看到相同的操作序列，这些操作序列以相同的顺序出现在Raft到应用程序的upcall中，之后它们以相同的顺序被本地应用程序应用到本地的状态中。假设操作是确定的（比如一个随机数生成操作就不是确定的），所有副本节点的状态，最终将会是完全一样的。我们图中的Key-Value数据库，就是Raft论文中说的状态（也就是Key-Value数据库的多个副本最终会保持一致）。





<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250421090454174.png" alt="image-20250421090454174" style="zoom:50%;" />





<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250421090627919.png" alt="image-20250421090627919" style="zoom:50%;" />





是的，作为实现者，这取决于你在什么时候将新的commit号发出。如果客户端请求很稀疏，那么Leader或许要发送一个心跳或者发送一条特殊的AppendEntries消息。如果客户端请求很频繁，那就无所谓了。因为如果每秒有1000个请求，那么下一条AppendEntries很快就会发出，你可以在下一条消息中带上新的commit号，而不用生成一条额外的消息。额外的消息代价还是有点高的，反正你要发送别的消息，可以把新的commit号带在别的消息里



## ✅ 原因：我们要找的是 “**最大的、可以安全提交的日志索引**”

这就是 Raft 的设计目标：

> 🔍 **找出满足条件的最大 N，使得：**
>
> - 有过半节点的 `matchIndex[i] ≥ N`
> - `log[N].term == currentTerm`

满足这两个条件后，才允许将 `commitIndex = N`。



### ✅ 场景回顾：

```
yaml


复制编辑
Index      : 7   8   9   10
Term       : 2   3   3    4
matchIndex:
  A (Leader):     ✓   ✓   ✓   ✓
  B         :     ✓   ✓   ✓   ✓
  C         :     ✓   ✓   ✗   ✗
  D         :     ✓   ✓   ✓   ✗
  E         :     ✓   ✓   ✓   ✓
```

当前：

- `term = 4`，新 Leader 是 A；
- 新 Leader 的日志为 log[7...10]；
- 日志在 7/8/9 都被多数节点保存了，但只有 log[10] 是 term=4；
- 因为 Raft **只允许提交当前任期内产生的日志**，所以 log[9], log[8], log[7] 虽然 quorum 拥有，但不能提交。

------

### 🧠 所以：当选之初，新 Leader 的 `commitIndex` 应是多少？

Raft 并**不会**在当选时自动计算 `commitIndex`。

- **默认是旧值：由磁盘恢复而来的旧 `commitIndex`**，也可能是 `0`（如果节点从头开始）；
- **必须通过向 follower 发送 AppendEntries，然后通过 matchIndex 收集，** 才能调用 `maybeCommit()` 来更新。

------

### ✅ 正确做法：

```
go


复制编辑
// 选举成功时
rf.commitIndex = 0 // 初始化为 0 或者持久化恢复值

// 等 follower 回复后
rf.maybeCommit() // 遍历 N，从大到小检查是否可提交
```

在你提供的这个例子中：

- **初始 commitIndex 可能是 0（如从头恢复）**
- Leader 向所有 follower 发送 AppendEntries；
- 收到 matchIndex 后，尝试推进 commitIndex；
- 但因为 log[10] 虽然 term==4，但复制节点数太少（< majority）；
- 所以最终 **commitIndex 仍然是 0**，直到后续 log[10] 被复制到多数。

------

### 



<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250421100911653.png" alt="image-20250421100911653" style="zoom:50%;" />





Raft生命周期中可能会有不同的Leader，它使用任期号（term number）来区分不同的Leader。Followers（非Leader副本节点）不需要知道Leader的ID，它们只需要知道当前的任期号。

这里需要注意的一点是，并不是说如果Leader没有故障，就不会有选举。但是如果Leader的确出现了故障，那么一定会有新的选举。这个选举的前提是其他服务器还在运行，因为选举需要其他服务器的选举定时器超时了才会触发。另一方面，如果Leader没有故障，我们仍然有可能会有一次新的选举。比如，如果网络很慢，丢了几个心跳，或者其他原因，这时，尽管Leader还在健康运行，我们可能会有某个选举定时器超时了，进而开启一次新的选举。在考虑正确性的时候，我们需要记住这点。所以这意味着，如果有一场新的选举，有可能之前的Leader仍然在运行，并认为自己还是Leader。例如，当出现网络分区时，旧Leader始终在一个小的分区中运行，而较大的分区会进行新的选举，最终成功选出一个新的Leader。这一切，旧的Leader完全不知道。所以我们也需要关心，在不知道有新的选举时，旧的Leader会有什么样的行为？

假设网线故障了，旧的Leader在一个网络分区中，这个网络分区中有一些客户端和少数（未过半）的服务器。在网络的另一个分区中，有着过半的服务器，这些服务器选出了一个新的Leader。旧的Leader会怎样，或者说为什么旧的Leader不会执行错误的操作？这里看起来有两个潜在的问题。第一个问题是，如果一个Leader在一个网络分区中，并且这个网络分区没有过半的服务器。那么下次客户端发送请求时，这个在少数分区的Leader，它会发出AppendEntries消息。但是因为它在少数分区，即使包括它自己，它也凑不齐过半服务器，所以它永远不会commit这个客户端请求，它永远不会执行这个请求，它也永远不会响应客户端，并告诉客户端它已经执行了这个请求。所以，如果一个旧的Leader在一个不同的网络分区中，客户端或许会发送一个请求给这个旧的Leader，但是客户端永远也不能从这个Leader获得响应。所以没有客户端会认为这个旧的Leader执行了任何操作。另一个更奇怪的问题是，有可能Leader在向一部分Followers发完AppendEntries消息之后就故障了，所以这个Leader还没决定commit这个请求。这是一个非常有趣的问题，我将会再花45分钟（下一节课）来讲。



如果一次选举成功了，整个集群的节点是如何知道的呢？当一个服务器赢得了一次选举，这个服务器会收到过半的认可投票，这个服务器会直接知道自己是新的Leader，因为它收到了过半的投票。但是其他的服务器并不能直接知道谁赢得了选举，其他服务器甚至都不知道是否有人赢得了选举。这时，（赢得了选举的）候选人，会通过心跳通知其他服务器。Raft论文的图2规定了，如果你赢得了选举，你需要立刻发送一条AppendEntries消息给其他所有的服务器。这条代表心跳的AppendEntries并不会直接说：我赢得了选举，我就是任期23的Leader。这里的表达会更隐晦一些。Raft规定，除非是当前任期的Leader，没人可以发出AppendEntries消息。所以假设我是一个服务器，我发现对于任期19有一次选举，过了一会我收到了一条AppendEntries消息，这个消息的任期号就是19。那么这条消息告诉我，我不知道的某个节点赢得了任期19的选举。所以，其他服务器通过接收特定任期号的AppendEntries来知道，选举成功了。





任何一条AppendEntries消息都会重置所有Raft节点的选举定时器。这样，只要Leader还在线，并且它还在以合理的速率（不能太慢）发出心跳或者其他的AppendEntries消息，Followers收到了AppendEntries消息，会重置自己的选举定时器，这样Leader就可以阻止任何其他节点成为一个候选人。所以只要所有环节都在正常工作，不断重复的心跳会阻止任何新的选举发生。当然，如果网络故障或者发生了丢包，不可避免的还是会有新的选举。但是如果一切都正常，我们不太可能会有一次新的选举。

如果一次选举选出了0个Leader，这次选举就失败了。有一些显而易见的场景会导致选举失败，例如太多的服务器关机或者不可用了，或者网络连接出现故障。这些场景会导致你不能凑齐过半的服务器，进而也不能赢得选举，这时什么事也不会发生。

一个导致选举失败的更有趣的场景是，所有环节都在正常工作，没有故障，没有丢包，但是候选人们几乎是同时参加竞选，它们分割了选票（Split Vote）。假设我们有一个3节点的多副本系统，3个节点的选举定时器几乎同超时，进而期触发选举。首先，每个节点都会为自己投票。之后，每个节点都会收到其他节点的RequestVote消息，因为该节点已经投票给自己了，所以它会返回反对投票。这意味着，3个节点中的每个节点都只能收到一张投票（来自于自己）。没有一个节点获得了过半投票，所以也就没有人能被选上。接下来它们的选举定时器会重新计时，因为选举定时器只会在收到了AppendEntries消息时重置，但是由于没有Leader，所有也就没有AppendEntries消息。所有的选举定时器重新开始计时，如果我们不够幸运的话，所有的定时器又会在同一时间到期，所有节点又会投票给自己，又没有人获得了过半投票，这个状态可能会一直持续下去。

Raft不能完全避免分割选票（Split Vote），但是可以使得这个场景出现的概率大大降低。Raft通过为选举定时器随机的选择超时时间来达到这一点。我们可以这样来看这种随机的方法。假设这里有个时间线，我会在上面画上事件。在某个时间，所有的节点收到了最后一条AppendEntries消息。之后，Leader就故障了。我们这里假设Leader在发出最后一次心跳之后就故障关机了。所有的Followers在同一时间重置了它们的选举定时器，因为它们大概率在同一时间收到了这条AppendEntries消息。

它们都重置了自己的选举定时器，这样在将来的某个时间会触发选举。但是这时，它们为选举定时器选择了不同的超时时间。

假设故障的旧的Leader是服务器1，那么服务器2（S2），服务器3（S3）会在这个点为它们的选举定时器设置随机的超时时间。

<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250421110247668.png" alt="image-20250421110247668" style="zoom:50%;" />

<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250421110300625.png" alt="image-20250421110300625" style="zoom:50%;" />

这个图里的关键点在于，因为不同的服务器都选取了随机的超时时间，总会有一个选举定时器先超时，而另一个后超时。假设S2和S3之间的差距足够大，先超时的那个节点（也就是S2）能够在另一个节点（也就是S3）超时之前，发起一轮选举，并获得过半的选票，那么那个节点（也就是S2）就可以成为新的Leader。大家都明白了随机化是如何去除节点之间的同步特性吗？

这里对于选举定时器的超时时间的设置，需要注意一些细节。一个明显的要求是，选举定时器的超时时间需要至少大于Leader的心跳间隔。这里非常明显，假设Leader每100毫秒发出一个心跳，你最好确认所有节点的选举定时器的超时时间不要小于100毫秒，否则该节点会在收到正常的心跳之前触发选举。所以，选举定时器的超时时间下限是一个心跳的间隔。实际上由于网络可能丢包，这里你或许希望将下限设置为多个心跳间隔。所以如果心跳间隔是100毫秒，你或许想要将选举定时器的最短超时时间设置为300毫秒，也就是3次心跳的间隔。所以，如果心跳间隔是这么多（两个AE之间），那么你会想要将选举定时器的超时时间下限设置成心跳间隔的几倍，在这里。



那超时时间的上限呢？因为随机的话都是在一个范围内随机，那我们应该在哪设置超时时间的上限呢？在一个实际系统中，有几点需要注意。



首先，这里的最大超时时间影响了系统能多快从故障中恢复。因为从旧的Leader故障开始，到新的选举开始这段时间，整个系统是瘫痪了。尽管还有一些其他服务器在运行，但是因为没有Leader，客户端请求会被丢弃。所以，这里的上限越大，系统的恢复时间也就越长。这里究竟有多重要，取决于我们需要达到多高的性能，以及故障出现的频率。如果一年才出一次故障，那就无所谓了。如果故障很频繁，那么我们或许就该关心恢复时间有多长。这是一个需要考虑的点。

另一个需要考虑的点是，不同节点的选举定时器的超时时间差（S2和S3之间）必须要足够长，使得第一个开始选举的节点能够完成一轮选举。这里至少需要大于发送一条RPC所需要的往返（Round-Trip）时间。



或许需要10毫秒来发送一条RPC，并从其他所有服务器获得响应。如果这样的话，我们需要设置超时时间的上限到足够大，从而使得两个随机数之间的时间差极有可能大于10毫秒。

在Lab2中，如果你的代码不能在几秒内从一个Leader故障的场景中恢复的话，测试代码会报错。所以这种场景下，你们需要调小选举定时器超时时间的上限。这样的话，你才可能在几秒内完成一次Leader选举。这并不是一个很严格的限制。

这里还有一个小点需要注意，每一次一个节点重置自己的选举定时器时，都需要重新选择一个随机的超时时间。也就是说，不要在服务器启动的时候选择一个随机的超时时间，然后反复使用同一个值。因为如果你不够幸运的话，两个服务器会以极小的概率选择相同的随机超时时间，那么你会永远处于分割选票的场景中。所以你需要每次都为选举定时器选择一个不同的随机超时时间。



学生提问：槽位10和11的请求必然执行成功了吗？ Robert教授：对于槽位11，甚至对于槽位10，我们不能从Log中看出来Leader在故障之前到底执行到了哪一步。有一种可能是Leader在发送完AppendEntries之后就立刻故障了，所以Leader没能收到其他副本的确认，相应的请求也就不会commit，进而也就不会执行这个请求，所以它也就不会发出增加了的commit值，其他副本也就可能也没有执行这个请求。所以完全可能槽位10和槽位11的请求没有被执行。如果Raft能知道这些，那么丢弃槽位10和槽位11的Log也是合法的，因为它们没有被commit。但是从Log上看，没有办法否认这些请求被commit了。换句话说，这些请求可能commit了。所以Raft必须认为它们已经被commit了，因为完全有可能，Leader是在对这些请求走完完整流程之后再故障。所以这里，我们不能排除Leader已经返回响应给客户端的可能性，只要这种可能性存在，我们就不能将槽位10和槽位11的Log丢弃，因为客户端可能已经知道了这个请求被执行了。所以我们必须假设这些请求被commit了

这段对话是对 Raft 中一个非常**微妙但关键的语义保证**的阐释：**Raft 系统无法单凭日志内容判断哪些日志是否已经被 committed 和执行**，但为了保证客户端**线性一致性（linearizability）**，Raft **必须保守地“假设它们已经 committed”**。

下面我们逐层展开解释。

------

## ✅ 背景：Raft 的 commit 语义是什么？

在 Raft 中，一条日志条目被认为是 **committed**，意味着它已经：

1. 被写入了 Leader 的日志；
2. **并被复制到过半数的服务器（quorum）**；
3. Leader 便会设置 `commitIndex`；
4. Leader 和所有 Follower 会 apply 到状态机；
5. Leader 将结果（如响应）返回给客户端。

只有执行完第 2 步，Raft 系统才对外认为这条日志是“可见的”。

------

## ❓问题提出：槽位 10 和 11 的日志到底有没有被执行？

Robert 教授的意思是：

> 即使日志 10 和 11 存在于 Leader 的 log 中，我们不能确定它们是否已经 **被大多数副本确认 / 被 commit / 被客户端看到了响应**，因为有一个可能性是：

- Leader 写入了日志；
- 发送了 `AppendEntries`；
- **还没收到足够的 `Success` 响应，就宕机了**；
- 那么这些日志就不被认为是 committed；
- 因此 **不应该被 apply 到状态机**。

------

## 🔁 然而，问题转折在这里：

我们作为系统观察者，如果只看日志文件（log[]），**我们看不出 Leader 是否已经收到了多数回复**，也看不出是否：

> - Leader 已经更新了 commitIndex；
> - Leader 已经向客户端返回了响应。

------

## 📌 Raft 的设计原则：**只要存在可能性，就不能丢弃日志条目**

Robert 教授的核心观点是：

> 即使我们无法确认日志 10 和 11 是否已经被 committed，**我们必须保守地“假设它们可能已经 committed”**，以保证：

### ✅ 客户端线性一致性（linearizability）

因为：

- 客户端可能已经收到了 Leader 发回的成功响应；
- 如果系统在重启后 **删除了这些日志**，就会造成已确认操作 **“被撤销”**，这会**破坏线性一致性**；
- 客户端会观察到系统“回滚”了一个已经返回成功的写操作，**这在一致性系统中是绝对不能容忍的。**

------

## 🧠 举个真实例子帮助理解

1. 客户端发送：`PUT x=5`，被写入槽位 10；
2. Leader 写入 log[10]，并发出 AppendEntries；
3. Leader 收到 quorum 回复，更新 commitIndex=10；
4. Leader 返回响应“成功”；
5. **立刻宕机，还没来得及发 `commitIndex=10` 给 follower**。

此时系统重启：

- follower 们日志里都有 log[10]，但没有 commitIndex；
- **我们无法从日志判断 log[10] 是不是被 commit 了**；
- 但客户端已经拿到返回值了；
- 所以 **我们必须保守地保留 log[10]**，等待新 Leader 来确认。

------

## 🔐 这就是为何 Raft 必须要求：

### ❗**日志条目只能被删除/覆盖在它未被 committed 的情况下；**

> 一旦存在可能被 commit 的日志（哪怕不确定），也不能轻易清除，必须等新 Leader 根据 quorum 来确认。

------

## ✅ 总结：Raft 的谨慎提交语义

| 问题                                         | 答案                                                         |
| -------------------------------------------- | ------------------------------------------------------------ |
| 槽位 10 和 11 的日志是否一定被 commit 了？   | ❌ 不一定                                                     |
| 我们能从日志中判断 commit 状态吗？           | ❌ 不能，必须通过 quorum 决策判断                             |
| 为什么不能删除槽位 10 和 11 的日志？         | ✅ 因为它们可能已经被客户端看到，需要保守处理                 |
| 如果我们删了未 commit 的日志，客户端会怎样？ | ❌ 可能看到“写成功但后来消失”，违反线性一致性                 |
| Raft 的处理策略是什么？                      | **保守假设日志可能被 commit**，直到新 Leader 依据 quorum 判断 |

------

如果你想深入探究 **新 Leader 如何确定哪些旧日志可以提交 or 必须回滚**，可以继续深入 **conflict resolution** 与 **Leader completeness** 的逻辑。我也可以贴出实际 Go 代码中如何避免误删未 commit 日志的写法，继续聊？







> **系统中“已提交”的最高日志条目的索引（index）** —— 即：**过半节点持有的、可以安全 apply 到状态机的最大日志索引**。

------

## ✅ 回答核心：

> **`commitIndex` 从 0 开始，是为了表示系统“尚未提交任何日志”。**
>
> 0 是一个自然的哨兵初始值，表示“当前没有任何日志被提交”。

------

## 🧠 更具体地解释：

### 1️⃣ commitIndex 的初始值为什么是 0？

- Raft 中 `log[]` 索引从 **1** 开始（也就是第一条有效日志的 index 是 1）；
- 在系统初始化时，还**没有任何日志被提交**，也没有 apply 到状态机；
- 所以用 `commitIndex = 0` 表示“尚未 commit 任意日志”，是一个自然的“空前缀”。

这相当于你在处理数据库时使用空事务号、或者在数组中设定 `-1` 表示“无效索引”。

------

### 2️⃣ commitIndex 是 “包含性索引”（inclusive index）

它的语义是：

> **“我已经提交了所有 ≤ commitIndex 的日志”**

所以当你有：

```
go


复制编辑
commitIndex = 0
```

就意味着：

> **“我什么都还没提交”**

而一旦有：

```
go


复制编辑
commitIndex = 3
```

就表示：

> **“我已经提交并可以应用 log[1], log[2], log[3]”**

------

### 3️⃣ 和 lastApplied 搭配自然

Raft 的状态机要求：

```
go


复制编辑
for lastApplied < commitIndex {
    lastApplied++
    apply(log[lastApplied])
}
```

如果初始值是：

```
go


复制编辑
lastApplied = 0
commitIndex = 0
```

就代表“还没有任何条目可以被 apply”，不会进入循环，逻辑自然成立。

------

### 4️⃣ 快照（Snapshot）场景更容易管理

在进行快照（Snapshot）时，`commitIndex` 会更新为：

```
go


复制编辑
commitIndex = lastIncludedIndex
```

例如你做了一个快照：

```
go


复制编辑
lastIncludedIndex = 10
```

说明你已经提交并应用了日志 [1, ..., 10]，那就：

```
go


复制编辑
commitIndex = 10
lastApplied = 10
```

如果 commitIndex 是从 1 开始，这种 “无日志时如何初始化” 就变得麻烦了。

------

## ✅ 总结对照表



| 状态变量            | 含义                                       | 初始值 | 启动意义                        |
| ------------------- | ------------------------------------------ | ------ | ------------------------------- |
| `log[]`             | 日志数组，索引从 1 开始                    | `[]`   | 第一个有效条目的索引为 1        |
| `commitIndex`       | **已提交的最大日志索引**（包含性）         | `0`    | 代表“当前无任何日志被提交”      |
| `lastApplied`       | **最后被应用到状态机的日志索引**（包含性） | `0`    | 应用状态从 0 开始，每次向前推进 |
| `lastIncludedIndex` | 快照中最新的日志索引                       | `0`    | 初始无快照                      |

------

### ✅ 所以 commitIndex 从 0 开始的 **核心理由是**：

1. **语义明确**：0 表示“当前未提交任何日志”；
2. **逻辑清晰**：与 `log[1:]` 索引划分、状态机应用配合自然；
3. **实现简单**：从 0 开始可以避免多写一堆边界特殊处理；
4. **与快照机制统一**：快照中也会将 commitIndex 设置为 `lastIncludedIndex`，初始为 0。