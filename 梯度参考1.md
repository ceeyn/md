\# 将前4个梯度的数据结合在一起作为特征 X = np.hstack((grad0, grad1, grad2, grad3))

x = [400,4 * 371]

两个代码段在实现功能上是类似的，但存在一些细微的差异：

1. **特征组合方式**：

   - 第一段代码使用 `np.vstack((grad0, grad1, grad2, grad3)).T` 将梯度特征组合在一起。
   - 第二段代码使用 `np.hstack((grad0, grad1, grad2, grad3))` 将梯度特征组合在一起。

   在这两个方法中，`vstack` 和 `hstack` 的行为略有不同。对于你的数据，`hstack` 是正确的选择，因为每个梯度特征是 371 行 400 列的数组。`hstack` 会将这些特征在列方向上合并，形成 371 行 1600 列的特征矩阵。

2. 

```python
import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.model_selection import KFold, train_test_split, cross_val_predict
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
import matplotlib.pyplot as plt

# 假设 grad0, grad1, grad2, grad3 是 371x400 的数组，每行为一个人的数据
# 假设 age 是长度为 371 的一维数组

grad0 = np.array(grad0)
grad1 = np.array(grad1)
grad2 = np.array(grad2)
grad3 = np.array(grad3)
age = np.array(age)

# 确保所有数据长度一致
assert grad0.shape[0] == grad1.shape[0] == grad2.shape[0] == grad3.shape[0] == len(age)

# 将前4个梯度的数据结合在一起作为特征
X = np.hstack((grad0, grad1, grad2, grad3))

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 定义训练和验证函数
def train_and_validate(X_train, y_train, X_test, y_test):
    # 定义SVR模型和参数网格
    svr = SVR(kernel='linear', C=1.0, gamma='scale')
    
    # 使用嵌套的10折交叉验证在发现组上训练模型
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    y_pred_discovery = cross_val_predict(svr, X_train, y_train, cv=kf)
    
    # 在整个发现组上训练模型
    svr.fit(X_train, y_train)
    
    # 预测验证组的年龄
    y_pred_validation = svr.predict(X_test)
    
    # 计算两个组的Spearman相关性和MAE
    corr_discovery, _ = spearmanr(y_train, y_pred_discovery)
    mae_discovery = mean_absolute_error(y_train, y_pred_discovery)
    corr_validation, _ = spearmanr(y_test, y_pred_validation)
    mae_validation = mean_absolute_error(y_test, y_pred_validation)
    
    return corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation

# 重复随机分配和预测分析100次
num_iterations = 100
spearman_corrs = []
maes = []

for i in range(num_iterations):
    # 随机分配参与者到发现组和验证组
    X_discovery, X_validation, y_discovery, y_validation = train_test_split(X_scaled, age, test_size=0.5, random_state=i)
    
    # 训练和验证模型
    corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation = train_and_validate(
        X_discovery, y_discovery, X_validation, y_validation)
    
    spearman_corrs.append(corr_validation)
    maes.append(mae_validation)

# 计算平均Spearman相关性和MAE
mean_spearman_corr = np.mean(spearman_corrs)
mean_mae = np.mean(maes)

# 输出结果
print(f"平均Spearman相关性 = {mean_spearman_corr:.2f}")
print(f"平均MAE = {mean_mae:.2f}")

# 可选: 绘制相关性和MAE分布
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(spearman_corrs, bins=20, edgecolor='k')
plt.xlabel('Spearman相关性')
plt.ylabel('次数')
plt.title('Spearman相关性分布')

plt.subplot(1, 2, 2)
plt.hist(maes, bins=20, edgecolor='k')
plt.xlabel('MAE')
plt.ylabel('次数')
plt.title('MAE分布')

plt.tight_layout()
plt.show()

```





```
import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.model_selection import KFold, cross_val_predict, GridSearchCV
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
import matplotlib.pyplot as plt

# 确保你有 grad3 数据
# 这里假设 grad3 是你已经提取好的第四个梯度
grad0 = np.array(grad0)
grad1 = np.array(grad1)
grad2 = np.array(grad2)
grad3 = np.array(grad3)
age = np.array(age)

# 将 grad0, grad1, grad2 和 grad3 结合在一起作为特征
X = np.vstack((grad0, grad1, grad2, grad3)).T

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 将数据分为发现组和验证组
np.random.seed(42)  # 为了结果可重复
indices = np.random.permutation(len(age))
split_point = len(age) // 2
discovery_indices = indices[:split_point]
validation_indices = indices[split_point:]

X_discovery = X_scaled[discovery_indices]
y_discovery = age[discovery_indices]
X_validation = X_scaled[validation_indices]
y_validation = age[validation_indices]

# 定义训练和验证函数
def train_and_validate(X_train, y_train, X_test, y_test):
    # 定义SVR模型和参数网格
    svr = SVR()
    param_grid = {
        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
        'C': [0.1, 1, 10, 100],
        'gamma': ['scale', 'auto']
    }
    
    # 使用网格搜索进行超参数优化
    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_absolute_error')
    grid_search.fit(X_train, y_train)
    best_svr = grid_search.best_estimator_
    
    # 使用最佳参数在发现组上进行嵌套的10折交叉验证
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    y_pred_discovery = cross_val_predict(best_svr, X_train, y_train, cv=kf)
    
    # 在整个发现组上训练最佳模型
    best_svr.fit(X_train, y_train)
    
    # 预测验证组的年龄
    y_pred_validation = best_svr.predict(X_test)
    
    # 计算两个组的Spearman相关性和MAE
    corr_discovery, _ = spearmanr(y_train, y_pred_discovery)
    mae_discovery = mean_absolute_error(y_train, y_pred_discovery)
    corr_validation, _ = spearmanr(y_test, y_pred_validation)
    mae_validation = mean_absolute_error(y_test, y_pred_validation)
    
    return corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation

# 使用定义的函数进行训练和验证
corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation = train_and_validate(
    X_discovery, y_discovery, X_validation, y_validation)

# 输出结果
print(f"发现组: Spearman相关性 = {corr_discovery:.2f}, MAE = {mae_discovery:.2f}")
print(f"验证组: Spearman相关性 = {corr_validation:.2f}, MAE = {mae_validation:.2f}")

# 可选: 绘制结果
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.scatter(y_discovery, cross_val_predict(SVR(kernel='linear', C=1.0), X_discovery, y_discovery, cv=10))
plt.plot([y_discovery.min(), y_discovery.max()], [y_discovery.min(), y_discovery.max()], 'k--', lw=2)
plt.xlabel('实际年龄')
plt.ylabel('预测年龄')
plt.title('发现组')

plt.subplot(1, 2, 2)
plt.scatter(y_validation, y_pred_validation)
plt.plot([y_validation.min(), y_validation.max()], [y_validation.min(), y_validation.max()], 'k--', lw=2)
plt.xlabel('实际年龄')
plt.ylabel('预测年龄')
plt.title('验证组')

plt.tight_layout()
plt.show()

```



```
import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
import matplotlib.pyplot as plt

# 确保你有 grad3 数据
# 这里假设 grad3 是你已经提取好的第四个梯度
grad0 = np.array(grad0)
grad1 = np.array(grad1)
grad2 = np.array(grad2)
grad3 = np.array(grad3)
age = np.array(age)

# 将 grad0, grad1, grad2 和 grad3 结合在一起作为特征
X = np.vstack((grad0, grad1, grad2, grad3)).T

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 定义训练和验证函数
def train_and_validate(X_train, y_train, X_test, y_test):
    # 定义SVR模型和参数网格
    svr = SVR(kernel='linear', C=1.0, gamma='scale')
    
    # 使用嵌套的10折交叉验证在发现组上训练模型
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    y_pred_discovery = cross_val_predict(svr, X_train, y_train, cv=kf)
    
    # 在整个发现组上训练模型
    svr.fit(X_train, y_train)
    
    # 预测验证组的年龄
    y_pred_validation = svr.predict(X_test)
    
    # 计算两个组的Spearman相关性和MAE
    corr_discovery, _ = spearmanr(y_train, y_pred_discovery)
    mae_discovery = mean_absolute_error(y_train, y_pred_discovery)
    corr_validation, _ = spearmanr(y_test, y_pred_validation)
    mae_validation = mean_absolute_error(y_test, y_pred_validation)
    
    return corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation

# 重复随机分配和预测分析100次
num_iterations = 100
spearman_corrs = []
maes = []

for i in range(num_iterations):
    # 随机分配参与者到发现组和验证组
    X_discovery, X_validation, y_discovery, y_validation = train_test_split(X_scaled, age, test_size=0.5, random_state=i)
    
    # 训练和验证模型
    corr_discovery, mae_discovery, corr_validation, mae_validation, y_pred_validation = train_and_validate(
        X_discovery, y_discovery, X_validation, y_validation)
    
    spearman_corrs.append(corr_validation)
    maes.append(mae_validation)

# 计算平均Spearman相关性和MAE
mean_spearman_corr = np.mean(spearman_corrs)
mean_mae = np.mean(maes)

# 输出结果
print(f"平均Spearman相关性 = {mean_spearman_corr:.2f}")
print(f"平均MAE = {mean_mae:.2f}")

# 可选: 绘制相关性和MAE分布
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(spearman_corrs, bins=20, edgecolor='k')
plt.xlabel('Spearman相关性')
plt.ylabel('次数')
plt.title('Spearman相关性分布')

plt.subplot(1, 2, 2)
plt.hist(maes, bins=20, edgecolor='k')
plt.xlabel('MAE')
plt.ylabel('次数')
plt.title('MAE分布')

plt.tight_layout()
plt.show()

```



分性别

```
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# 从CSV文件中加载AI_array数据
AI_array = np.loadtxt('/Users/haozhipeng/PycharmProjects/gradient/new_fc/528/AI_array.csv', delimiter=',')

# 读取xlsx 提取age和性别
file_path = '/Users/haozhipeng/MATLAB/data/aging_fc/pt_select.xlsx'
df = pd.read_excel(file_path, usecols=[1, 2], header=None)
age = df.iloc[:, 0].values
gender = df.iloc[:, 1].values  # Assuming 0 for female and 1 for male

# 使用AI_array数据作为特征
features = AI_array

# 将性别标签转换为二进制格式（假设0代表女性，1代表男性）
labels = np.array(gender)

# 标准化特征
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2, random_state=42)

# 定义参数网格
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}

# 使用网格搜索进行超参数调优
svc = SVC()
grid_search = GridSearchCV(svc, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# 输出最佳参数
print("Best parameters found: ", grid_search.best_params_)

# 使用最佳参数进行预测
best_svc = grid_search.best_estimator_
y_pred_train = best_svc.predict(X_train)
y_pred_test = best_svc.predict(X_test)

# 计算准确度
train_accuracy = accuracy_score(y_train, y_pred_train)
test_accuracy = accuracy_score(y_test, y_pred_test)

print(f'Train Accuracy: {train_accuracy}')
print(f'Test Accuracy: {test_accuracy}')

```



分年龄组

```
import numpy as np
import pandas as pd
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from scipy.io import loadmat
from brainspace.gradient import GradientMaps
from sklearn.utils.class_weight import compute_class_weight

# 加载.mat文件中的功能连接矩阵数据
data = loadmat('/Users/haozhipeng/MATLAB/data/aging_fc/combined_fc.mat')
combined_function_data_array = np.array(data["combined_function_data_array"])

# 提取功能连接矩阵列表
rows_list = [combined_function_data_array[i, 0] for i in range(combined_function_data_array.shape[0])]

# 读取xlsx 提取age
file_path = '/Users/haozhipeng/MATLAB/data/aging_fc/pt_select.xlsx'
df = pd.read_excel(file_path, usecols=[1], header=None)
age = df.iloc[:, 0].values

# 设置梯度映射参数
n_components = 10  # 梯度成分数
approach = 'dm'    # 渐进映射方法

# 初始化列表以存储结果
grad0, grad1, grad2, grad3, grad4, grad5, grad6, grad7, grad8, grad9 = [], [], [], [], [], [], [], [], [], []

# 计算每个功能连接矩阵的梯度
for fc_matrix in rows_list:
    gm = GradientMaps(n_components=n_components, approach=approach)
    gm.fit(fc_matrix)
    emb = gm.gradients_
    grad0.append(emb[:, 0])
    grad1.append(emb[:, 1])
    grad2.append(emb[:, 2])
    grad3.append(emb[:, 3])
    grad4.append(emb[:, 4])
    grad5.append(emb[:, 5])
    grad6.append(emb[:, 6])
    grad7.append(emb[:, 7])
    grad8.append(emb[:, 8])
    grad9.append(emb[:, 9])

# 将列表转换为numpy数组
grad0 = np.array(grad0)
grad1 = np.array(grad1)
grad2 = np.array(grad2)
grad3 = np.array(grad3)
grad4 = np.array(grad4)
grad5 = np.array(grad5)
grad6 = np.array(grad6)
grad7 = np.array(grad7)
grad8 = np.array(grad8)
grad9 = np.array(grad9)

# 确保所有数据长度一致
assert grad0.shape[0] == grad1.shape[0] == grad2.shape[0] == grad3.shape[0] == grad4.shape[0] == grad5.shape[0] == grad6.shape[0] == grad7.shape[0] == grad8.shape[0] == grad9.shape[0] == len(age)

# 定义年龄组标签
age_groups = {
    'children': list(range(14)),
    'adolescents': list(range(14, 55)),
    'adults': list(range(55, 284)),
    'elderly': list(range(284, 369))
}

labels = np.zeros(len(age), dtype=int)
labels[age_groups['children']] = 0
labels[age_groups['adolescents']] = 1
labels[age_groups['adults']] = 2
labels[age_groups['elderly']] = 3

# 使用前10个梯度的数据
X = np.hstack((grad0, grad1, grad2, grad3, grad4, grad5, grad6, grad7, grad8, grad9))

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 计算类别权重
class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)
class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}

# 将数据分为训练组和测试组
X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.3, random_state=42, stratify=labels)

# 定义训练和验证函数
def train_and_validate(X_train, y_train, X_test, y_test):
    # 定义随机森林模型和参数网格
    rf = RandomForestClassifier(class_weight=class_weight_dict)
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    
    # 使用网格搜索进行超参数优化
    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train, y_train)
    best_rf = grid_search.best_estimator_
    
    # 预测
    y_pred_train = best_rf.predict(X_train)
    y_pred_test = best_rf.predict(X_test)
    
    # 计算准确率
    train_accuracy = accuracy_score(y_train, y_pred_train)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    
    # 生成分类报告
    train_report = classification_report(y_train, y_pred_train)
    test_report = classification_report(y_test, y_pred_test)
    
    # 生成混淆矩阵
    train_conf_matrix = confusion_matrix(y_train, y_pred_train)
    test_conf_matrix = confusion_matrix(y_test, y_pred_test)
    
    return train_accuracy, test_accuracy, train_report, test_report, train_conf_matrix, test_conf_matrix

# 使用定义的函数进行训练和验证
train_accuracy, test_accuracy, train_report, test_report, train_conf_matrix, test_conf_matrix = train_and_validate(X_train, y_train, X_test, y_test)

# 输出结果
print(f"训练组准确率 = {train_accuracy:.2f}")
print(f"测试组准确率 = {test_accuracy:.2f}")
print("\n训练组分类报告:\n", train_report)
print("测试组分类报告:\n", test_report)
print("训练组混淆矩阵:\n", train_conf_matrix)
print("测试组混淆矩阵:\n", test_conf_matrix)

# 可选: 绘制混淆矩阵
def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = 'd'
    thresh = cm.max() / 2.
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, format(cm[i, j], fmt),
                 ha="center", va="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel

```





```
import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.model_selection import KFold, GridSearchCV, train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from scipy.stats import spearmanr
import matplotlib.pyplot as plt
from joblib import Parallel, delayed
from scipy.io import loadmat
from brainspace.gradient import GradientMaps

# 加载.mat文件中的功能连接矩阵数据
data = loadmat('/Users/haozhipeng/MATLAB/data/aging_fc/combined_fc.mat')
combined_function_data_array = np.array(data["combined_function_data_array"])

# 提取功能连接矩阵列表
rows_list = [combined_function_data_array[i, 0] for i in range(combined_function_data_array.shape[0])]

# 读取xlsx 提取age
file_path = '/Users/haozhipeng/MATLAB/data/aging_fc/pt_select.xlsx'
df = pd.read_excel(file_path, usecols=[1], header=None)
age = df.iloc[:, 0].values

# 设置梯度映射参数
n_components = 10  # 梯度成分数
approach = 'dm'    # 渐进映射方法

# 初始化列表以存储结果
grad0, grad1, grad2, grad3, grad4, grad5, grad6, grad7, grad8, grad9 = [], [], [], [], [], [], [], [], [], []

# Estimate individual-level gradient components
for fc_matrix in rows_list:
    gm = GradientMaps(n_components=n_components, approach=approach)
    gm.fit(fc_matrix)

    emb = gm.gradients_
    grad0.append(emb[:, 0])
    grad1.append(emb[:, 1])
    grad2.append(emb[:, 2])
    grad3.append(emb[:, 3])
    grad4.append(emb[:, 4])
    grad5.append(emb[:, 5])
    grad6.append(emb[:, 6])
    grad7.append(emb[:, 7])
    grad8.append(emb[:, 8])
    grad9.append(emb[:, 9])

# 将列表转换为numpy数组
grad0 = np.array(grad0)
grad1 = np.array(grad1)
grad2 = np.array(grad2)
grad3 = np.array(grad3)
grad4 = np.array(grad4)
grad5 = np.array(grad5)
grad6 = np.array(grad6)
grad7 = np.array(grad7)
grad8 = np.array(grad8)
grad9 = np.array(grad9)

# 确保所有数据长度一致
assert grad0.shape[0] == grad1.shape[0] == grad2.shape[0] == grad3.shape[0] == grad4.shape[0] == grad5.shape[0] == grad6.shape[0] == grad7.shape[0] == grad8.shape[0] == grad9.shape[0] == len(age)

# 将10个梯度的数据结合在一起作为特征
X = np.hstack((grad0, grad1, grad2, grad3, grad4, grad5, grad6, grad7, grad8, grad9))

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 特征选择，只保留前 4000 个最佳特征（因为我们有10个梯度，每个400个特征）
selector = SelectKBest(f_regression, k=4000)
X_selected = selector.fit_transform(X_scaled, age)

# 将数据分为发现组和验证组
np.random.seed(42)  # 为了结果可重复
indices = np.random.permutation(len(age))
split_point = len(age) // 2
discovery_indices = indices[:split_point]
validation_indices = indices[split_point:]

X_discovery = X_selected[discovery_indices]
y_discovery = age[discovery_indices]
X_validation = X_selected[validation_indices]
y_validation = age[validation_indices]

# 定义训练和验证函数
def train_and_validate(X, y, K=5):
    kf = KFold(n_splits=K, shuffle=True, random_state=42)
    predict_label_all = []
    testlabel_all = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        
        # 定义SVR模型和参数网格
        svr = SVR()
        param_grid = {
            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],
            'C': [0.1, 1, 10, 100],
            'gamma': ['scale', 'auto']
        }
        
        # 使用网格搜索进行超参数优化
        grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_absolute_error')
        grid_search.fit(X_train, y_train)
        best_svr = grid_search.best_estimator_
        
        # 预测
        predict_label = best_svr.predict(X_test)
        
        # 收集所有预测标签和真实标签
        predict_label_all.extend(predict_label)
        testlabel_all.extend(y_test)
    
    # 计算Spearman相关性和MAE
    corr, _ = spearmanr(predict_label_all, testlabel_all)
    mae = mean_absolute_error(testlabel_all, predict_label_all)
    
    return corr, mae, np.array(predict_label_all), np.array(testlabel_all), best_svr

# 使用定义的函数进行训练和验证
corr, mae, predict_label_all, testlabel_all, model_svr = train_and_validate(X_selected, age)

# 输出结果
print(f"Spearman相关性 = {corr:.2f}, MAE = {mae:.2f}")

# 可选: 绘制结果
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.scatter(testlabel_all, predict_label_all)
plt.plot([min(testlabel_all), max(testlabel_all)], [min(testlabel_all), max(testlabel_all)], 'k--', lw=2)
plt.xlabel('实际年龄')
plt.ylabel('预测年龄')
plt.title('预测结果')

plt.tight_layout()
plt.show()

# 置换测试
def permutation_test(predict_label_all, testlabel_all, num_permutations=1000):
    real_r, _ = spearmanr(predict_label_all, testlabel_all)
    
    # 随机置换标签进行置换测试
    def permutation(i):
        np.random.seed(i)
        np.random.shuffle(testlabel_all)
        return spearmanr(predict_label_all, testlabel_all)[0]
    
    surr_r = Parallel(n_jobs=-1)(delayed(permutation)(i) for i in range(num_permutations))
    p_real = np.sum(np.array(surr_r) > real_r) / num_permutations
    
    return p_real, real_r

p_real, real_r = permutation_test(predict_label_all, testlabel_all)

print(f"真实相关性 = {real_r:.2f}, 置换测试p值 = {p_real:.4f}")

```

置入PDF文件后点上角的嵌入，点击图片右键取消编组，再点击右键释放剪切版，重复这一步。AI中如何才能编辑PDF里面的文字_pdf在ai里怎么编辑 在ai用文字工具可分别输入上万种文字，文字取决与你电脑里安装得文本与AI安装的文本。正常情况下





### . 导入必要的库

```
python
复制代码
import numpy as np
import nibabel as nib  # 用于处理神经影像数据的库
from sklearn.metrics import pairwise_distances  # 用于计算成对距离的库
```

- `numpy`: 用于处理数组和矩阵操作。
- `nibabel`: 用于加载和处理神经影像数据（.nii 文件）。
- `sklearn.metrics.pairwise_distances`: 用于计算成对距离，这里用于计算余弦相似性。

### 2. 加载数据并进行 Fisher's z-to-r 变换

```
python
复制代码
dcon = np.tanh(nib.load('HCP_S900_820_rfMRI_MSMAll_groupPCA_d4500ROW_zcorr.dconn.nii').data)
```

- `nib.load()`: 加载 `.nii` 格式的连接组数据文件。
- `np.tanh()`: 对数据进行 Fisher's z-to-r 变换。`np.tanh` 函数是双曲正切函数，其输出范围是 [-1, 1]，用于将 Fisher z 相关系数转换为原始相关系数。

### 3. 获取节点数量

```
python
复制代码
N = dcon.shape[0]
```

- `dcon.shape[0]`: 获取连接矩阵的行数，即节点的数量。

### 4. 生成90百分位数的阈值

```
python
复制代码
perc = np.array([np.percentile(x, 90) for x in dcon])
```

- `np.percentile(x, 90)`: 计算每行数据的第90百分位数。
- 将每行的90百分位数存储在 `perc` 数组中。

### 5. 阈值处理

```
python
复制代码
for i in range(dcon.shape[0]):
  print "Row %d" % i
  dcon[i, dcon[i,:] < perc[i]] = 0    
```

- 遍历每一行，将小于90百分位数的值设置为0。
- `dcon[i, dcon[i,:] < perc[i]] = 0`: 对于第 `i` 行，将其小于阈值的元素设置为0。

### 6. 检查最小值

```
python
复制代码
print "Minimum value is %f" % dcon.min()
```

- 打印处理后的连接矩阵中的最小值。

### 7. 统计负值

```
python
复制代码
neg_values = np.array([sum(dcon[i,:] < 0) for i in range(N)])
print "Negative values occur in %d rows" % sum(neg_values > 0)
```

- `neg_values`: 统计每一行中负值的数量。
- 打印包含负值的行数。

### 8. 将负值设置为0

```
python
复制代码
dcon[dcon < 0] = 0
```

- 将所有负值设置为0。

### 9. 计算余弦相似性

```
python
复制代码
aff = 1 - pairwise_distances(dcon, metric='cosine')
```

- `pairwise_distances(dcon, metric='cosine')`: 计算每对节点之间的余弦距离。
- `1 - pairwise_distances`: 将余弦距离转换为余弦相似性，余弦相似性的范围为 [0, 1]，其中1表示完全相似，0表示完全不相似。

### 10. 保存相似性矩阵

```
python
复制代码
np.save('gradient_data/conn_matrices/cosine_affinity.npy', aff)
```

- 将计算得到的余弦相似性矩阵保存为 `.npy` 文件，便于后续分析使用。





```
python
复制代码
# 计算功能连接性矩阵
corr_matrix = np.corrcoef(img_mmp.T)
```

`np.corrcoef` 函数用于计算相关系数矩阵。这里的 `img_mmp.T` 表示对 `img_mmp` 矩阵进行转置（即行和列互换），然后计算其列之间的相关性。相关系数矩阵表示每对变量（这里是脑区时间序列）之间的线性相关性，值在-1到1之间。

```
python
复制代码
# 将相关系数矩阵中的大于0.99999的值设置为1
corr_matrix[corr_matrix > 0.99999] = 1
```

这行代码将相关系数矩阵中所有大于0.99999的值设置为1。这样做是为了防止在Fisher Z变换时出现极端值，因为相关系数接近于1会导致变换后的值趋近于无穷大。

```
python
复制代码
# 对相关系数矩阵进行Fisher Z变换
fc = np.arctanh(corr_matrix)
```

`np.arctanh` 是反双曲正切函数（Fisher Z变换）。Fisher Z变换用于将相关系数从[-1, 1]范围转换到实数范围，从而使其在统计分析中更接近于正态分布。这个变换有助于在后续分析中使用线性模型或其他统计方法。

```
python
复制代码
# 将无穷大的值设置为0
fc[fc == np.inf] = 0
```

这行代码将Fisher Z变换后得到的无穷大值设置为0。尽管前面的步骤已经将相关系数限制在-1到1之间，但仍然可能出现极端情况，因此需要这一步骤来确保数据的稳定性和有效性。

### 总结：

1. **计算相关系数矩阵**：通过对时间序列数据进行转置，然后计算其列之间的相关性，得到一个反映各脑区之间相关性的矩阵。
2. **限制相关系数的极端值**：将大于0.99999的相关系数值设置为1，以防止在变换时出现无穷大值。
3. **进行Fisher Z变换**：将相关系数转换为实数，以便在后续分析中使用。
4. **处理无穷大值**：将变换后得到的无穷大值设置为0，确保数据稳定性。







方法二：

### 处理每个被试者的数据

```
python
复制代码
path = '../../data/data_autism/1_fc/ABIDE-I/'
for i in range(len(dir_num)):
  file = path+dir_num[i]+'/hcp_processed/'+file_name[i]+'_func.dtseries.nii'
  if os.path.exists(file):
    img = nib.load(file).get_fdata()
    print('executing sub.'+dir_num[i]+'......')
    img_mmp = np.zeros((img.shape[0],360))
    img_cortex=img[:,0:18722]
    for m in range(img.shape[0]):
      for n in range(360):
        img_mmp[m][n]=np.mean(img_cortex[m][mmp_lr_clean==n+1])
    corr_matrix = np.corrcoef(img_mmp.T)
    corr_matrix[corr_matrix>0.99999] = 1
    fc = np.arctanh(corr_matrix)
    fc[fc == np.inf] = 0
    np.savetxt('../results/fc/full/'+dir_num[i]+'.csv', fc, delimiter=',')
    fc_LL = fc[0:180,0:180]
    fc_RR = fc[180:360,180:360]
    fc_LR = fc[0:180,180:360]
    fc_RL = fc[180:360,0:180]
    fc_LLRR = fc_LL - fc_RR
    fc_LRRL = fc_LR - fc_RL
    np.savetxt('../results/fc/LL/'+dir_num[i]+'.csv', fc_LL, delimiter=',')
    np.savetxt('../results/fc/RR/'+dir_num[i]+'.csv', fc_RR, delimiter=',')
    np.savetxt('../results/fc/LR/'+dir_num[i]+'.csv', fc_LR, delimiter=',')
    np.savetxt('../results/fc/RL/'+dir_num[i]+'.csv', fc_RL, delimiter=',')
    np.savetxt('../results/fc/intra/'+dir_num[i]+'.csv', fc_LLRR, delimiter=',')
    np.savetxt('../results/fc/inter/'+dir_num[i]+'.csv', fc_LRRL, delimiter=',')
```

- 加载每个被试者的fMRI数据。
- 打印被试者ID。
- 创建一个新的矩阵`img_mmp`来存储每个区域的平均时间序列。
- 使用相关系数计算功能连接矩阵`corr_matrix`。
- 将极端值处理为1，并进行Fisher Z变换。
- 将无穷大值处理为0。
- 保存完整的功能连接矩阵和不同部分的子矩阵







### 功能连接组梯度

将预处理的时间序列进行分区后，我们得到了时间序列*分区的数组。我们首先使用时间序列计算分区之间的皮尔逊相关性，并使用 Fisher z 变换将*r*值转换为*z*值。这将为每个个体生成 360*360 的功能连接 (FC) 矩阵。然后，为了计算功能连接组梯度，我们使用非线性流形学习算法对 FC 矩阵进行降维。与功能梯度不对称框架 [ [31](https://www.nature.com/articles/s41380-023-02220-x#ref-CR31) ] 一致，我们将每个个体梯度与模板梯度 (即左-左组级梯度) 进行对齐，并使用 Procrustes 旋转使个体梯度具有可比性 [ [30](https://www.nature.com/articles/s41380-023-02220-x#ref-CR30) ]。为了在年轻人中获得无年龄或性别偏见的无偏左-左组级梯度模板，我们使用了人类功能连接组项目 S1200 版本 (HCP S1200) 的数据。这之前已经做过了 [ [31](https://www.nature.com/articles/s41380-023-02220-x#ref-CR31) ]。简而言之，我们对 1104 名受试者的 HCP S1200 FC 矩阵取平均值，并根据平均左-左 FC 矩阵计算组级梯度。第一个特征向量反映单峰-跨峰梯度 (G1)、感觉-视觉梯度 (G2) 和多需求梯度 (G3)，分别解释总方差的 24.1%、18.4% 和 15.1%。

梯度分析是在 BrainSpace [ [30](https://www.nature.com/articles/s41380-023-02220-x#ref-CR30) ] 中执行的，这是一个用于大脑降维的 Matlab/python 工具箱（https://brainspace.readthedocs.io/en/latest/pages/install.html）。梯度是连接组的低维特征向量，沿着梯度，通过许多超阈值边或少量非常强的边紧密相连的皮质节点靠得更近。同样，连接性较小的节点相距较远。这反映了功能连接配置文件的相似性/相异性，可以解释为以前三个梯度构建的公共坐标空间 [ [33](https://www.nature.com/articles/s41380-023-02220-x#ref-CR33) ] 形式描述的区域之间的功能整合和分离。这种方法属于图拉普拉斯算子家族，其名称源自扩散图嵌入中点之间的欧几里得距离的等价性 [ [32](https://www.nature.com/articles/s41380-023-02220-x#ref-CR32) , [88](https://www.nature.com/articles/s41380-023-02220-x#ref-CR88) ]。它由单个参数 α 控制，该参数反映了采样点密度对流形的影响（*α* = 0，影响最大；*α = 1，无影响）。在前人研究 [* [32](https://www.nature.com/articles/s41380-023-02220-x#ref-CR32) ] 的基础上，我们遵循建议并设置*α* = 0.5，这个选择保留了嵌入空间中数据点之间的全局关系，并且被认为对协方差矩阵中的噪声具有相对的鲁棒性。FC 矩阵中前 10% 的值被用作进入计算的阈值，这与之前的研究 [ [4](https://www.nature.com/articles/s41380-023-02220-x#ref-CR4)，[31](https://www.nature.com/articles/s41380-023-02220-x#ref-CR31)，[32](https://www.nature.com/articles/s41380-023-02220-x#ref-CR32) ] 一致。

### 不对称指数

为了量化左右半球的差异，我们选择左右作为不对称指数（AI）[ [31](https://www.nature.com/articles/s41380-023-02220-x#ref-CR31) ]。我们没有选择标准化的AI，即（左-右）/（左+右），因为梯度方差（标准化角度）既有负值也有正值[ [14](https://www.nature.com/articles/s41380-023-02220-x#ref-CR14) ]，而标准化的AI会夸大差异值或导致分母不连续[ [89](https://www.nature.com/articles/s41380-023-02220-x#ref-CR89) ]。标准化的AI与相关系数大于0.9的非标准化AI非常相似[ [31](https://www.nature.com/articles/s41380-023-02220-x#ref-CR31) ]。对于半球内模式，AI是使用从左到左的连接组梯度减去从右到右的连接组梯度来计算的。正的AI分数表示半球特征向左占主导地位，而负的AI分数表示向右占主导地位。对于半球间模式，我们使用从左到右的连接组梯度减去从右到左的连接组梯度来计算AI。我们在图中 Cohen's d 分数中添加了一个“减号”，以便于查看侧化方向（即向左或向右）。





### 梯度分析。

首先通过计算皮质表面任意两对顶点之间的皮尔逊相关系数，为每次访视的每次静息扫描生成顶点级功能连接 (FC) 矩阵 (20,484×20,484)，然后使用双曲正切函数获得相应的 Fisher z 变换值。然后对一次访视内的两个重测 FC Fisher z 矩阵取平均值，以提高生成个体 FCz 矩阵的信噪比和可靠性（[81](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r81)）。接下来对个体 FCz 矩阵取平均值，以形成组级 FCz 矩阵。仅保留每个顶点的前 10% 连接，以与之前的研究保持一致（3,28 [） ，矩阵中](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r3)[的](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-bib99)其他元素设置为 0 以强制稀疏性。这些组级稀疏矩阵已通过国家基础科学数据中心的科学数据库发布（[99](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r28)）。然后，我们计算 FCz 矩阵任意两行之间的余弦距离，并用 1 减去该距离以获得对称相似矩阵。

在相似度矩阵上实现扩散图嵌入（[28,58 ](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r28)[）](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r58)以导出梯度（ https://www.github.com/NeuroanatomyAndConnectivity/gradient_analysis ）。梯度按解释的方差排序（[*SI 附录*](http://www.pnas.org/lookup/doi/10.1073/pnas.2024448118#supplementary-materials)[，](https://www.github.com/NeuroanatomyAndConnectivity/gradient_analysis)[图 S1](http://www.pnas.org/lookup/doi/10.1073/pnas.2024448118#supplementary-materials)）。为了确定跨年龄组梯度的对应关系，我们计算了 1 年间隔年龄组中任意两对梯度图之间的 Pearson 相关系数（[图 2 ](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig02)[*A*](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig02)）。首先将梯度图在跨年龄组的梯度内连接起来，例如，将每个年龄组的梯度一图连接起来形成一个矩阵，然后组合梯度矩阵以生成最终的全局梯度矩阵。梯度图是最终矩阵中的行向量，按年龄排序，即前 11 行是从 7 岁到 17 岁的第一个梯度图。

[图 1](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig01)和[图 2](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig02)总结了儿童和青少年组的梯度图。[图 3](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig03)列出了跨 1 年间隔年龄组的前六个梯度图。为了量化跨年龄组的梯度转换，我们提取了默认网络区域内的梯度*z*值，如 Yeo 等人（[3 ）对 Schaefer 及其同事（ ](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r3)[67](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#core-r67) ）的 400 个分区功能图谱的平均七网络解决方案所总结的那样（[图 3B *）*](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig03)。为了说明默认网络的梯度级别成熟度，我们对六个梯度成熟图中七个功能网络边界内的成熟值取平均值，并将它们汇总在每个网络的雷达图中（[图 3C*和*](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig03)SI[*附录*、图 S2](http://www.pnas.org/lookup/doi/10.1073/pnas.2024448118#supplementary-materials)）。在每个雷达图中，六个维度指的是每个梯度的平均成熟年龄。[图 4](https://www.pnas.org/doi/full/10.1073/pnas.2024448118#fig04)中的箱线图显示了梯度值在大型大脑网络中的分布方式，按每个网络内的中值排序。









### 结果

### Gradient 1 - Quadratic Model

**回归模型**:

- Quadratic model: std ~ age + age^2 + sex

**主要结果**:

- **R-squared**: 0.048 表示模型解释了约4.8%的标准差的方差。

- **Adj. R-squared**: 0.040 调整后的R²略低，表明模型复杂度增加后解释的方差有些减少。

- **F-statistic**: 6.161，P值（Prob (F-statistic)）为0.000429，表明整体模型显著。

- 系数

  :

  - **const** (常数项): 0.0748，表示基线标准差。
  - **age**: 0.0006，P值为0.004，表明年龄对标准差的影响显著正相关。
  - **sex**: -0.0005，P值为0.757，表明性别对标准差的影响不显著。
  - **age^2**: -4.732e-06，P值为0.029，表明二次项的影响显著但较小，说明标准差与年龄之间存在非线性关系。

**其他统计量**:

- **Omnibus** 和 **Jarque-Bera (JB) tests** 显示模型残差分布存在偏差。
- **Durbin-Watson**: 1.792 表示没有显著的自相关性。

### Gradient 2 - Linear Model

**回归模型**:

- Linear model: std ~ age + sex

**主要结果**:

- **R-squared**: 0.013 表示模型解释了约1.3%的标准差的方差。

- **Adj. R-squared**: 0.008 调整后的R²略低。

- **F-statistic**: 2.474，P值（Prob (F-statistic)）为0.0857，表明整体模型不显著。

- 系数

  :

  - **const** (常数项): 0.0569，表示基线标准差。
  - **age**: -3.982e-05，P值为0.030，表明年龄对标准差的影响显著负相关。
  - **sex**: -0.0007，P值为0.397，表明性别对标准差的影响不显著。

**其他统计量**:

- **Omnibus** 和 **Jarque-Bera (JB) tests** 显示模型残差分布存在偏差。
- **Durbin-Watson**: 2.195 表示没有显著的自相关性。

### 结论

1. **Gradient 1**:
   - 模型为二次模型，表明年龄对标准差的影响存在非线性关系。
   - 年龄对标准差的影响显著正相关，同时存在二次项的负相关。
   - 性别对标准差的影响不显著。
   - 模型解释了约4.8%的标准差的方差，表明模型的解释能力有限。
2. **Gradient 2**:
   - 模型为线性模型，表明年龄对标准差的影响为线性关系。
   - 年龄对标准差的影响显著负相关。
   - 性别对标准差的影响不显著。
   - 模型解释了约1.3%的标准差的方差，表明模型的解释能力更低。

### 
