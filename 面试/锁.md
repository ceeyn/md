

cas应用：1.自旋锁 2.atomicInteger， 3.LongAdder 4.AQS

cas底层：cas-》unsafe-》intel x86 cpu原子指令 cmpxchg指令 -》对总线加锁保持原子性

syn：cas设置ownner，waitset，entryset，优化 4：偏向（对象头是线程），轻量级锁（对象头是lock record地址）、锁膨胀成重型锁（对象头是monitor地址），锁粗化、锁消除、自适应自旋

reentrantlock：公平/非公平，定时锁尝试、可中断、读写锁，超时释放



````
CAS（Compare And Swap，比较并交换）是并发编程中一种常用的无锁原子操作，用于解决多线程之间的数据竞争问题。CAS 的实现依赖于 CPU 的底层指令，通过硬件保证操作的原子性。下面详细介绍 CAS 的底层工作原理及其实现流程。

### 1. CAS 的基本概念
CAS 操作涉及三个参数：内存地址（`V`），旧的预期值（`A`）和新的值（`B`）。它的执行过程是：
- 如果当前内存地址 `V` 中的值等于预期值 `A`，则将 `V` 更新为新值 `B`。
- 如果不相等，则不更新，并返回 `V` 的当前值。

CAS 操作通过比较和交换的方式，确保在多线程环境下，某个值在被更新前没有发生变化，从而实现原子性更新。这样可以保证在多线程环境下，只有一个线程能够成功更新值，避免了加锁的开销。

### 2. CAS 在 Java 中的实现
在 Java 中，CAS 操作通常通过 `sun.misc.Unsafe` 类来实现，`Unsafe` 是 Java 提供的一个包含底层内存操作的方法的类，能够直接操作内存。

- `Unsafe` 类提供了 `compareAndSwapInt`、`compareAndSwapLong` 等方法，这些方法使用了底层 CPU 的原子操作来确保线程安全。我们可以通过这些方法直接调用 CPU 提供的指令进行内存操作。
  
```java
public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);
```

- `compareAndSwapInt` 方法就是通过调用底层的 CPU 指令来实现比较并交换的。

### 3. CAS 的底层实现：Intel x86 指令 `cmpxchg`
Java 中 `Unsafe` 类的 CAS 操作最终依赖于硬件级别的指令，特别是在 Intel x86 架构的 CPU 上，使用的是 `cmpxchg`（Compare and Exchange）指令来实现原子操作。`cmpxchg` 是一条支持原子性的汇编指令，具体过程如下：

- `cmpxchg` 指令的作用是将两个值进行比较，如果相等，则交换它们的值。
- 该指令能够保证整个操作是原子的，即不会被中断。它的典型操作模式为：
  1. 比较寄存器（通常为 `EAX` 或 `RAX`）中的值与指定内存地址中的值。
  2. 如果二者相等，就将寄存器中的新值写入该内存地址。
  3. 如果不相等，则将内存地址中的值复制到寄存器中，表示交换失败。

在汇编代码中，`cmpxchg` 的指令格式为：
```assembly
cmpxchg [address], reg
```
这意味着比较内存地址（`address`）中的值与寄存器中的值（`reg`），如果相等，则将寄存器中的值写回到内存地址。

### 4. 原子性保证：总线锁或缓存锁
为了确保 `cmpxchg` 操作的原子性，CPU 需要采取一定的机制来防止其他线程或 CPU 核心在操作期间对内存进行修改。主要有两种机制来实现：

#### 4.1 总线锁（Bus Lock）
在较早期的系统中，CPU 使用总线锁来确保原子性。这种方法会锁住内存总线，【在 `cmpxchg` 指令执行期间，所有其他对该内存地址的访问都会被阻塞。这种机制能够保证 `cmpxchg` 指令在整个操作期间不会受到其他内存操作的影响。】

当总线锁定时，所有对内存总线的请求都会被暂时挂起，直到锁定释放。这可以防止多个 CPU 核心同时对同一片内存区域进行修改，从而确保数据一致性。

但是，总线锁的缺点在于它会导致所有其他处理器停止对内存的访问，性能开销很大，因此在现代处理器中较少使用。

#### 4.2 缓存锁（Cache Line Locking）
现代 CPU 更倾向于使用缓存一致性协议来实现原子操作，称为缓存锁。在 CPU 缓存中，有一组缓存行用于存储内存数据。通过缓存锁，CPU 可以将【一个缓存行锁定为“独占模式”，这样可以防止其他处理器修改该缓存行的内容。】
当 `cmpxchg` 操作访问的内存地址在 CPU 的缓存中时，CPU 使用缓存一致性协议（如 MESI 协议）来确保该缓存行在操作期间不会被其他处理器访问。例如，当某个处理器执行 `cmpxchg` 时，会将该内存地址的缓存行锁定，直到操作完成。这样可以实现比总线锁更加高效的原子操作。

缓存一致性协议能够使 `cmpxchg` 操作在不同核心间实现协同，从而保证多个核心之间的数据一致性。这也使得现代 CPU 能够更高效地实现并发访问的原子性。

### 5. CAS 的应用和问题
CAS 操作在 Java 的并发包中被广泛使用，例如 `java.util.concurrent` 包中的许多类，像 `AtomicInteger`、`AtomicLong`、`ConcurrentHashMap` 等，都是通过 CAS 来实现线程安全的。

#### 5.1 优点
- **无锁化**：CAS 操作使得我们能够在不使用锁的情况下实现线程安全的数据更新，避免了锁的上下文切换开销，提高了性能。
- **高性能**：CAS 操作直接利用 CPU 提供的硬件级别的原子性支持，在大多数情况下比传统的锁实现要高效。

#### 5.2 问题
- **ABA 问题**：在 CAS 操作中，可能会发生“ABA”问题：即某个变量的值从 `A` 变为 `B`，然后又变回 `A`，在这种情况下，CAS 操作无法检测到值的变化，因为它只比较值是否相等。为了解决 ABA 问题，可以引入版本号（如 `AtomicStampedReference`）。
- **自旋开销**：如果有多个线程频繁竞争同一个资源，CAS 操作可能会导致一些线程不断重试，形成“自旋”，进而导致 CPU 的消耗较大。
- **只能保证一个变量的原子性**：CAS 只对一个变量进行操作，无法直接处理多个变量的原子性，这时候通常会使用锁或者其他机制来解决。

### 6. 总结
- **CAS 的实现**：Java 中通过 `Unsafe` 类调用 CPU 的 `cmpxchg` 指令来实现 CAS 操作。
- **底层工作机制**：`cmpxchg` 确保原子性的方式主要依赖于总线锁或者缓存锁，现代处理器更倾向于使用缓存锁来保证操作的原子性，减少总线的使用，提高性能。
- **CAS 的优点**：无锁、高效，适合用在多线程场景中。
- **CAS 的缺点**：存在 ABA 问题、自旋等待可能导致 CPU 消耗过高、只能作用于单个变量。

CAS 是一种重要的无锁编程技术，通过硬件级别的支持来保证数据一致性，适用于高并发场景中的原子操作。
````

cas缺陷：1.空轮询 2.aba

悲观锁：1.reentrantlock java层面 2.synchronized jvm层面

<img src="/Users/moon/Library/Application Support/typora-user-images/image-20240911222051173.png" alt="image-20240911222051173" style="zoom: 33%;" />





synchronized【1.自旋锁优化（获取不到锁时自旋10次，因为java线程模型是内核线程模型，尽可能避免用户态到内核态切换）2.自适应自旋】

```
`synchronized` 是 Java 中用来实现线程同步的关键字，它确保同一时间只有一个线程可以执行 `synchronized` 方法或块，从而避免多线程对共享资源进行并发修改导致的数据不一致问题。在 Java 中，`synchronized` 的底层实现历经了多次优化，以提高性能和适应高并发的需求。其中一些重要的优化技术包括 **自旋锁** 和 **自适应自旋**。以下是它们的详细解释。

### 1. 自旋锁优化
自旋锁是为了优化在多线程争夺锁时的性能问题而引入的技术。当一个线程尝试获取锁时，如果锁已经被其他线程持有，那么传统的方式是将当前线程挂起（阻塞），等待锁释放后再唤醒。但是在 Java 中，线程的挂起和唤醒需要经过操作系统内核的管理，这意味着会发生从用户态到内核态的切换，这种切换的开销是相当大的。

为了解决这个问题，Java 引入了 **自旋锁** 的概念。在锁已经被持有的情况下，线程不会立即阻塞，而是会进行一段时间的**自旋**，即反复检查锁的状态。具体来说，自旋是一种忙等待，它使线程在短时间内不断循环，直到锁被释放。这样，如果锁只被短时间占用，线程无需阻塞，而是在 CPU 上快速循环几次后就可以直接获得锁，避免了线程从用户态切换到内核态的高昂成本。

#### 自旋锁的优化机制
- **自旋次数**：Java 中的自旋锁会自旋 **10 次**，即当线程尝试获取锁但锁被其他线程持有时，它不会立即放弃，而是会做 10 次循环尝试。这是因为 Java 线程模型属于内核线程模型（即每个 Java 线程是对应一个 OS 的线程），内核线程的阻塞和唤醒涉及内核调度，开销较大。
- **减少线程切换的开销**：通过这种自旋的方式，Java 尽可能地减少线程的阻塞操作，避免了用户态到内核态的切换，尤其是当持锁时间非常短时，这种策略可以显著提高系统性能。

自旋锁的引入适合那些持锁时间非常短的场景。因为在短时间内持锁期间使用自旋，比进行线程挂起和恢复的开销要小得多。但是如果持锁时间较长，自旋会浪费大量的 CPU 资源，反而降低性能。因此，在 JDK 1.6 之后，Java 又引入了 **自适应自旋** 来进一步优化自旋锁的机制。

### 2. 自适应自旋
**自适应自旋** 是对固定自旋次数的一种改进。在 JDK 1.6 之后，Java 使用了更加智能的方式来动态地决定自旋的次数，以进一步提升性能。这种策略叫做 **自适应自旋**（Adaptive Spinning）。

#### 自适应自旋的工作原理
自适应自旋是基于前一次自旋锁的经验来决定自旋次数的。它的具体工作原理如下：
- **自适应调整**：与固定自旋次数不同，自适应自旋会根据锁的获取情况动态调整自旋的次数。如果一个线程在自旋后成功获取了锁，那么下次该线程就会自旋更长时间，因为它发现自旋是有希望获取锁的。
- 如果线程在某次自旋之后未能获取锁，那么系统会减少下一次自旋的次数，甚至直接放弃自旋而进入阻塞状态。
  
通过这种方式，自适应自旋可以根据系统的运行状态和锁的竞争情况，灵活调整自旋的行为，使得锁竞争的处理更加高效。

#### 典型的应用场景
- **低竞争且短期持锁**：在锁竞争不激烈的情况下（比如持锁时间非常短），自适应自旋可以有效避免线程的频繁阻塞和唤醒，提高 CPU 使用效率。
- **高竞争场景**：在锁竞争激烈的场景中，自适应自旋会动态调整策略，减少无效的自旋操作，从而避免浪费 CPU 资源。

### 自旋锁和自适应自旋的优缺点

#### 优点：
1. **减少用户态到内核态切换的开销**：通过自旋来避免线程阻塞，使得短期锁可以快速获取，减少了线程的上下文切换。
2. **性能提升**：特别是在持锁时间较短的场景中，自旋锁避免了阻塞和唤醒的开销，显著提高了系统性能。
3. **动态适应**：自适应自旋能够根据运行环境调整自旋次数，适应性更强，可以减少不必要的自旋开销。

#### 缺点：
1. **CPU 资源浪费**：自旋锁在持锁时间较长的情况下，线程会一直占用 CPU 资源进行自旋，这会导致 CPU 时间的浪费，对系统性能有负面影响。
2. **锁的竞争加剧时可能效果不佳**：如果锁的竞争非常激烈，大量线程同时进行自旋，会导致 CPU 负载增加，进而影响系统的整体性能。
3. **对持锁时间较长的场景不适用**：在锁占用时间较长的情况下，自旋操作比阻塞唤醒的开销更大，因为自旋浪费了 CPU 资源。因此，自旋锁一般适用于短期的锁定场景，而不是那些需要长时间持有锁的情况。

### 示例场景
假设我们有一个多线程环境，其中多个线程要同时访问一个共享资源。为了防止数据不一致，我们使用 `synchronized` 来确保同一时刻只有一个线程可以访问这个资源。

- 当线程 A 持有锁时，线程 B 和线程 C 也尝试获取该锁。在没有自旋锁的情况下，线程 B 和 C 会被立即阻塞（挂起），这意味着它们需要等待内核的调度，涉及用户态和内核态的切换，开销较大。
- 使用自旋锁后，线程 B 和 C 不会立即被阻塞，而是会进行几次自旋，尝试等待线程 A 释放锁。
  - 如果线程 A 在很短的时间内释放了锁，那么线程 B 或 C 就可以立即获取锁，而不需要进行上下文切换，节省了 CPU 开销。
  - 如果线程 A 持有锁的时间较长，那么自旋的线程最终也会进入阻塞状态，以避免浪费过多的 CPU 资源。

### 总结
- `synchronized` 在 Java 中通过引入自旋锁和自适应自旋来优化线程同步操作。
- 自旋锁会在获取不到锁时自旋几次（默认 10 次），这样可以尽量减少线程从用户态到内核态切换的开销，适合短期的锁竞争。
- 自适应自旋则根据前一次锁获取的情况动态调整自旋次数，适应性更强。
- 自旋锁和自适应自旋的优化措施有效提升了 `synchronized` 的性能，特别是在低锁竞争和短期锁持有的场景中，能够显著减少线程阻塞和唤醒带来的系统开销，提高程序运行效率。

这两种优化策略的核心目标是尽可能避免线程的阻塞操作，因为阻塞和唤醒操作涉及到系统级别的上下文切换，而上下文切换会带来较大的开销。因此，通过在持锁时间较短的情况下进行忙等待（自旋）操作，可以有效地提高锁的获取效率和程序的性能。
```

AQS

```java
// reentrantlock是披着lock接口，对程序员提供操作锁api，真正做事的是内部的aqs，至于锁/同步器的逻辑就是你继承aqs重写方法的逻辑
public class ReentrantLock implements Lock {
  
  public void lock() {
    // lock()->acquire()->tryAcquire()[内部调用unsafe的cas]->acquire(读写，可中断)->tryAcquire()->acquireQueued()[如果是排队第一个则再tryAcquire()]->shouldParkAfterFailedAcquire()[将前一个节点设为-1]->parkAndCheckInterrupt()[park]
    
    	sync.lock();
  }
  public void unlock() {
     // tryRelease() -> unparkSuccessor() -> 
    	sync.unlock();
  }
  
  private final Sync sync;
  
  private class Sync extends AbstractSynchronizedQueue {
    	// 内部类，内部重写了继承了AQS抽象类的一些方法，这些方法的逻辑就是你要借助AQS实现的锁/同步器逻辑，并对外部使用，典型的模版设计模式的体现。
    
  }
  
  
}
// AbstractOwnableSynchronizer 1.有一个owner 是thread类型
public abstract class AbstractSynchronizedQueue extends AbstractOwnableSynchronizer {
  	// 2.
  	volatile int state;
  	// 3.阻塞队列 lockSupport.park(),
  	// 4.等待队列
}
```



### 非公平锁比公平锁吞吐量更高

1.公平：线程获取锁时添加到阻塞队列末尾，运行状态由运行切换成阻塞，等到前面线程使用完锁唤醒后继，再由阻塞切换成运行，要进行两次线程上下文切换

2.非公平：cas直接竞争锁，竞争失败才会进入等待队列

非公平存在后申请但先获得锁的情况，但也提升了整体



### 锁底层：总线加锁、内存屏障

### 悲观锁底层：可能是cas+条件队列

循环依赖

````
在多核处理器系统中，硬件提供的 **总线锁**（bus lock）和 **内存屏障**（memory barrier）是两种关键的机制，用来保证多个处理器之间的同步，确保对共享数据的访问不会发生竞争条件（race condition）和数据不一致问题。这两种机制是多核处理器系统中并发控制和内存一致性协议的基础。

### 1. **总线锁（Bus Lock）**

总线锁（或称总线锁定机制）是一种由硬件提供的机制，通常用于确保在多核处理器系统中，当一个处理器对共享内存进行读写操作时，其他处理器无法同时访问该内存位置，从而避免并发访问引起的冲突。

#### 1.1 **总线锁的工作原理**

在多核系统中，每个核心都有自己的本地缓存（L1、L2 缓存），它们通过一个共享的系统总线与内存进行交互。当多个处理器同时访问内存时，如果没有适当的同步机制，可能会导致数据不一致的问题。例如，一个处理器写入数据到内存后，另一个处理器可能还在使用缓存中的旧数据。

为了避免这种情况，处理器使用总线锁来进行同步。总线锁的基本原理是，在进行读写操作时，处理器向总线发送一个特殊的锁请求，锁定内存位置，使得其他处理器不能同时访问该内存位置，直到当前操作完成。

具体步骤如下：
1. **请求锁定**：当一个处理器想要修改共享内存时，它通过总线发送一个锁请求（例如，`LOCK` 前缀指令），告诉其他处理器它需要独占访问该内存区域。
2. **总线控制**：一旦锁定操作成功，其他处理器的内存访问请求将被挂起，它们不能同时访问该内存区域。
3. **内存操作**：处理器执行内存的读写操作（例如写入共享数据）。
4. **释放锁定**：操作完成后，处理器释放锁，允许其他处理器访问该内存区域。

#### 1.2 **典型的硬件支持：LOCK 前缀**

处理器通过特定的指令来实现总线锁操作。在 x86 架构中，`LOCK` 前缀指令是一个常见的例子。`LOCK` 前缀告诉处理器将接下来的内存操作锁定在总线上。它确保在进行某些内存操作（如原子增减、比较交换等）时，其他处理器无法同时访问该内存位置。

例如，x86 架构上的 `LOCK` 前缀操作：

```asm
LOCK cmpxchg [memory_location], eax
```

这条指令执行原子比较并交换（CAS）操作，确保该操作在所有其他处理器上无法中断。这是通过总线锁实现的，它会阻塞其他处理器访问相关内存区域，直到当前处理器完成操作。

### 2. **内存屏障（Memory Barrier）**

内存屏障（又叫内存栅栏）是硬件提供的一种机制，用来强制执行对内存操作的顺序性，防止处理器重新排序内存访问指令。内存屏障在多核处理器系统中非常重要，它可以确保在一个处理器执行一组指令时，其他处理器看到内存访问操作的顺序和预期一致。

#### 2.1 **内存访问乱序与内存一致性**

现代处理器通常具有优化机制，比如指令重排序、延迟写入（write buffering）、延迟读取（read forwarding）等。这些优化提高了处理器的执行效率，但也可能导致内存访问的顺序发生变化，从而导致不同处理器看到不同的内存状态，产生 **内存一致性问题**。

举个例子，如果一个处理器 A 写入了某个共享变量，并且另一个处理器 B 读取了这个变量，理论上，B 应该能看到 A 最新写入的数据。然而，如果没有适当的同步机制，处理器 B 可能读取到旧值（由于缓存未更新），从而出现数据不一致的问题。

#### 2.2 **内存屏障的作用**

内存屏障（Memory Barrier）是强制处理器遵守特定内存操作顺序的机制。它确保内存访问指令的顺序性，不会被乱序执行。内存屏障可以分为以下几种类型：

- **全屏障（Full Barrier）**：也称为 `mfence`，确保屏障前的所有读写操作都完成后，才执行屏障后的操作。它强制前后的所有读写操作按顺序执行。
- **写屏障（Write Barrier）**：也称为 `sfence`，确保在屏障之前的所有写操作完成后，才允许屏障之后的写操作。
- **读屏障（Read Barrier）**：也称为 `lfence`，确保在屏障之前的所有读操作完成后，才允许屏障之后的读操作。

内存屏障通常由处理器提供，并且内核可以通过内存屏障指令来显式地插入屏障，确保对共享数据的访问按照预期顺序执行。

例如，在 Linux 内核中，内存屏障可以通过以下宏来实现：

```c
#define smp_mb() asm volatile("mfence" ::: "memory")
#define smp_rmb() asm volatile("lfence" ::: "memory")
#define smp_wmb() asm volatile("sfence" ::: "memory")
```

这些宏插入了相应的内存屏障指令，确保内存访问的顺序性。

#### 2.3 **内存屏障的使用场景**

- **自旋锁和互斥锁实现**：在多核环境中，自旋锁的实现需要内存屏障来确保锁状态的修改（例如 `xchg`）的顺序性，以防止处理器乱序执行。
- **信号量、条件变量**：当多个线程依赖共享数据时，内存屏障保证了某些写入操作在其他线程读取时已经完成。
- **原子操作**：在执行原子操作时，内存屏障可确保前后的内存访问顺序，避免出现不一致的结果。

### 3. **硬件支持的具体机制**

不同的处理器架构有不同的内存屏障和总线锁机制。以下是一些常见处理器架构对内存屏障和总线锁的支持：

#### 3.1 **x86 架构**

- **LOCK 前缀**：用于实现原子操作，确保操作的独占性，通过锁定总线来防止其他处理器访问相关内存区域。
- **内存屏障指令**：`mfence`、`sfence`、`lfence` 等用于确保内存操作的顺序性。

#### 3.2 **ARM 架构**

ARM 处理器使用 `dmb`（Data Memory Barrier）和 `dsb`（Data Synchronization Barrier）来实现内存屏障。

- **`dmb`**：确保所有数据操作完成后，再执行后续的操作，防止重排序。
- **`dsb`**：确保所有的数据访问指令完成后才返回，通常用于同步整个数据通道。

#### 3.3 **PowerPC 架构**

PowerPC 架构使用 `lwsync`（Lightweight Synchronization）和 `sync` 来实现内存屏障。

- **`lwsync`**：用于同步所有处理器的缓存，以确保对共享数据的一致访问。
- **`sync`**：用于确保缓存的一致性，确保所有的读写操作按顺序执行。

### 4. **总结**

总线锁和内存屏障是多核处理器中保证内存一致性和同步的重要机制：

- **总线锁**：通过硬件锁定内存位置，避免多个处理器同时访问共享内存，确保数据一致性。它通过特定的锁请求（例如 `LOCK` 前缀）来实现。
- **内存屏障**：强制执行内存操作的顺序性，防止处理器在优化时乱序执行，确保多核系统中不同处理器对内存的访问顺序一致。内存屏障指令如 `mfence`、`lfence`、`sfence` 在硬件中实现。

这些硬件机制确保了多核处理器在并发访问共享资源时的正确性和一致性，是现代操作系统和并发编程中的基础。
````







### 内核线程与用户态、内核态的关系

- **内核线程可以在用户态或内核态下运行**：
  - 内核线程不一定总是在内核态下运行。内核线程在执行一些系统任务（如管理资源、内存分配、设备驱动等）时，可能运行在内核态，因为这些任务涉及对硬件的直接访问。
  - 当内核线程为用户程序执行用户代码时，它也可以运行在用户态。例如，在Java程序中，一个Java线程（它通过内核线程实现）执行普通的Java代码时，实际上是处于用户态的。
  - 只有当内核线程需要执行特权操作（例如系统调用），它才会进入内核态。
- **用户线程运行在用户态**：
  - 用户线程只能运行在用户态，不能直接进入内核态。用户线程的所有操作，如调度、上下文切换等，都是通过用户级的库实现的，而不是通过操作系统内核。
  - 用户线程在执行特权操作时（比如I/O操作），会通过系统调用将控制权交给内核线程，由内核线程代表它执行进入内核态的操作。因此，用户线程本身并不直接进入内核态，而是依赖内核线程的帮助来完成这些操作。

###  用户线程和内核线程的区别

| 特性           | 用户线程（User Thread）                    | 内核线程（Kernel Thread）                                |
| -------------- | ------------------------------------------ | -------------------------------------------------------- |
| **创建和管理** | 由应用程序或用户级线程库管理。             | 由操作系统内核创建和管理。                               |
| **调度方式**   | 用户态调度，用户程序负责切换。             | 由操作系统内核调度，通常使用内核级调度算法。             |
| **上下文切换** | 上下文切换较快，无需用户态到内核态的切换。 | 上下文切换较慢，因为需要在用户态和内核态之间进行切换。   |
| **系统调用**   | 无法直接进行系统调用，需要依赖内核线程。   | 可以直接进行系统调用。                                   |
| **阻塞**       | 一个线程阻塞可能导致整个进程阻塞。         | 一个线程阻塞不会影响其他线程，操作系统可以调度其他线程。 |
| **开销**       | 低，线程操作无需操作系统的参与。           | 高，涉及系统调用，需要内核的参与。                       |

```
用户线程与内核线程的区别与关系
用户线程的优势和劣势：

优势：用户线程的创建、销毁和调度开销相对较小，因为它们不需要内核的直接参与，线程管理在用户级完成。
劣势：如果一个用户线程进行系统调用或阻塞，那么它所属的所有用户线程都会被阻塞，因为操作系统不知道用户线程的存在，它只会调度对应的内核线程。
内核线程的优势和劣势：

优势：内核线程可以直接由操作系统管理，可以利用多核 CPU 进行并行计算，即使一个内核线程阻塞了，操作系统也可以调度其他内核线程。
劣势：内核线程的创建和销毁开销较大，调度需要进行用户态和内核态之间的切换，这会引入额外的上下文切换开销。
```



## JAVA线程方法

<img src="/Users/moon/Library/Application Support/typora-user-images/image-20241129145835876.png" alt="image-20241129145835876" style="zoom:50%;" />

### sleep 不会释放锁

**虽然sleep函数使当前线程让出了CPU, 但是, 当前线程仍然持有它所获得的监视器锁, 这与同时让出CPU资源和监视器锁资源的wait方法是不一样的**。



**Thread.sleep、synchronized和Object.wait**底层分别是利用线程**SleepEvent**和**ParkEvent**对象的**park**方法实现线程阻塞的。因为这2个对象实际是一个类型的，因此我们就一起来看一下其park方法究竟做了什么

找到**SleepEvent**和**ParkEvent**的定义，从后面的注释就可以发现，ParkEvent就是供synchronized()使用的，而SleepEvent则是供Thread.sleep使用的：

以linux系统为例，在头文件中可以看到PlatformEvent的具体定义：

我们关注的重点首先是2个private的对象，一个**pthread_mutex_t，表示操作系统级别的信号量**，一个**pthread_cond_t，表示操作系统级别的条件变量**

其次是定义了3个方法，**park()、unpark()、park(jlong millis)**，控制线程的阻塞和继续执行

接着我们就需要去看**park**方法的具体实现，这里我们主要关注3个系统底层方法的调用

pthread_mutex_lock(_mutex)：锁住信号量

status = pthread_cond_wait(_cond, _mutex)：释放信号量，并在条件变量上等待

status = pthread_mutex_unlock(_mutex)：释放信号量

https://kkewwei.github.io/elasticsearch_learning/2018/11/10/LockSupport%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/

### syn、wait、Park

#### park底层：计数器count、锁mutex、等待队列cond

park 操作：

1. 获取当前线程关联的 Parker 对象。
2. 将计数器置为 0，同时检查计数器的原值是否为 1，如果是则放弃后续操作。
3. 在互斥量上加锁。
4. 在条件变量上阻塞，同时释放锁并等待被其他线程唤醒，当被唤醒后，将重新获取锁。
5. 当线程恢复至运行状态后，将计数器的值再次置为 0。
6. 释放锁。

Parker::park主要做了如下事情:

- 检查_counter>0(别的线程调用过unpark), 则原子操作清零。线程不用睡眠并返回。
- 检查该线程是否有中断信号, 有的话,清掉并返回。
- 尝试通过pthread_mutex_trylock对_mutex加锁来达到线程互斥。
- 检查_counter是否>0, 若成立,说明第一步原子清零操作失败。检查park是否设置超时时间, 若设置了通过safe_cond_timedwait进行超时等待; 若没有设置,调用pthread_cond_wait进行阻塞等待。 这两个函数都在阻塞等待时都会放弃cpu的使用。 直到别的线程调用pthread_cond_signal唤醒
- 直接_counter=0清零。
- 通过pthread_mutex_unlock释放mutex的加锁。
  需要了解下: safe_cond_timedwait/pthread_cond_wait在执行之前肯定已经获取了锁_mutex, 在睡眠前释放了锁, 在被唤醒之前, 首先再取唤醒锁。

unpark 操作：

1. 获取目标线程关联的 Parker 对象（注意目标线程不是当前线程）。
2. 在互斥量上加锁。
3. 将计数器置为 1。
4. 唤醒在条件变量上等待着的线程。
5. 释放锁。

unpark()主要做了如下事情:

- 首先获取锁_mutex。
- 对_counter置为1, 而不管之前什么值, 这里说明无论多少函数调用unpark(), 都是无效的, 只会记录一次。
- 检查线程是否已经被阻塞了, 若已经阻塞了,调用pthread_cond_signal唤醒唤醒。
- 释放对_mutex的锁定。

https://www.cnblogs.com/aspirant/p/11470858.html

### syn底层采取_mutex，自旋锁、自适应自旋、锁消除、锁粗化

```
4 锁的优化
从JDK5引入了现代操作系统新增加的CAS原子操作（ JDK5中并没有对synchronized关键字做优化，而是体现在J.U.C中，所以在该版本concurrent包有更好的性能 ），从JDK6开始，就对synchronized的实现机制进行了较大调整，包括使用JDK5引进的CAS自旋之外，还增加了自适应的CAS自旋、锁消除、锁粗化、偏向锁、轻量级锁这些优化策略。由于此关键字的优化使得性能极大提高，同时语义清晰、操作简单、无需手动关闭，所以推荐在允许的情况下尽量使用此关键字，同时在性能上此关键字还有优化的空间。

锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁。但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级。

在 JDK 1.6 中默认是开启偏向锁和轻量级锁的，可以通过-XX:-UseBiasedLocking来禁用偏向锁。

4.1 自旋锁
线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。

所以引入自旋锁，何谓自旋锁？ 

所谓自旋锁，就是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。

自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。自旋等待不能替代阻塞，虽然它可以避免线程切换带来的开销，但是它占用了CPU处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。

自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启，在JDK1.6中默认开启。同时自旋的默认次数为10次，可以通过参数-XX:PreBlockSpin来调整。

如果通过参数-XX:PreBlockSpin来调整自旋锁的自旋次数，会带来诸多不便。假如将参数调整为10，但是系统很多线程都是等你刚刚退出的时候就释放了锁（假如多自旋一两次就可以获取锁），是不是很尴尬。于是JDK1.6引入自适应的自旋锁，让虚拟机会变得越来越聪明。

4.2 适应性自旋锁
JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。那它如何进行适应性自旋呢？ 

线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。

有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。

4.3 锁消除
为了保证数据的完整性，在进行操作时需要对这部分操作进行同步控制，但是在有些情况下，JVM检测到不可能存在共享数据竞争，这是JVM会对这些同步锁进行锁消除。

锁消除的依据是逃逸分析的数据支持

如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是对于程序员来说这还不清楚么？在明明知道不存在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？虽然没有显示使用锁，但是在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如StringBuffer的append()方法，Vector的add()方法：

复制代码
public void vectorTest(){
    Vector<String> vector = new Vector<String>();
    for(int i = 0 ; i < 10 ; i++){
        vector.add(i + "");
    }

    System.out.println(vector);
}
复制代码
在运行这段代码时，JVM可以明显检测到变量vector没有逃逸出方法vectorTest()之外，所以JVM可以大胆地将vector内部的加锁操作消除。

4.4 锁粗化
在使用同步锁的时候，需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，这样做的目的是 为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。

在大多数的情况下，上述观点是正确的。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。

锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁

如上面实例：

vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。
```



### final可见性、不可变与volatile的可见性、可变性冲突

`final` 和 `volatile` 不能一起使用的原因在于它们的设计目标和功能特性相互冲突。让我们从两个关键字的目的和行为来解释这个问题。

````
### 1. **`final` 关键字的作用：**

   - **不可变性**：`final` 修饰的字段在对象被创建后，不能被修改。这意味着该字段必须在构造函数中初始化，且一旦初始化后，该字段的值永远不会改变。
   - **线程可见性保证**：`final` 修饰的字段在构造函数初始化完成后，其他线程对这个对象的任何访问都将看到该字段的最终值，且不会出现未初始化状态。这是因为 `final` 字段一旦初始化完成，它在其他线程中就能被安全地读取，保证可见性。

### 2. **`volatile` 关键字的作用：**

   - **可见性**：`volatile` 修饰的变量会告诉 JVM 和编译器，任何对该变量的读写操作必须直接在主内存中进行，不能缓存在线程的本地缓存中。因此，`volatile` 变量的值在多个线程之间总是同步可见的。
   - **可变性**：`volatile` 的主要用途是确保线程对该变量的修改能够立即对其他线程可见。也就是说，`volatile` 修饰的变量是可以多次被更新和修改的。

### 为什么 `final` 和 `volatile` 冲突？

- **`final` 保证不可变性**：`final` 保证变量在初始化之后不能再改变，它的核心作用是"只读"。在构造函数完成后，`final` 变量不能再被重新赋值或修改。

- **`volatile` 保证可见性和可变性**：`volatile` 则意味着该变量可能会被多个线程修改，且每个线程都能看到最新的值。因此，`volatile` 通常用于需要频繁更新和读取的变量。

### 两者冲突：

- `final` 强调"不能改变"，变量的值在构造完成后不能修改；
- `volatile` 强调"可见性"，允许变量值在不同线程间频繁更新。

因此，`final` 和 `volatile` 的设计目标是相反的。`final` 是为了使变量在对象生命周期内保持不变，而 `volatile` 是为了让变量在多线程中动态变化。因此，将它们一起使用没有意义。

### 示例：

```java
public class Example {
    private final volatile int myVar;  // 这是不合法的

    public Example(int value) {
        this.myVar = value;  // `final` 变量必须在构造函数中初始化
    }
}
```

- `final` 要求 `myVar` 只能在构造函数中被赋值，且赋值后不能改变；
- `volatile` 则意味着该变量可以在多个线程中频繁变化，因此二者无法共存。

### 总结：

`final` 和 `volatile` 的功能和用途是相互排斥的：`final` 确保不可变性，而 `volatile` 允许变量被频繁修改，因此不能同时应用于同一个字段。
````



### final：1.可见性（读写屏障），2.不可变性，3.内联，4.虚方法表（多态性）

好的，我将更深入地解释 `final` 的底层机制，涉及 Java 内存模型（Java Memory Model, JMM）、编译器优化、字节码指令和 JVM 对 `final` 变量的处理。

### 1. `final` 变量的底层机制

当 `final` 修饰字段（变量）时，其核心作用是在变量赋值后保证不可修改，同时在多线程环境下确保正确的可见性和发布顺序。下面逐步解释：

#### 1.1 编译期的优化
在 Java 编译期，编译器会对 `final` 变量进行优化：

- **常量折叠**（Constant Folding）：如果 `final` 变量在编译期已知，其值可以被编译器直接嵌入到代码中，这样可以减少运行时的计算。

例如，假设有以下代码：

```java
final int a = 10;
int b = a + 5;
```

编译器在编译时会直接将 `b` 计算为 `15`，省去了运行时的计算。我们来看一下字节码：

```java
0: iconst_5       // 常量值 5 入栈
1: bipush 10      // 常量值 10 入栈
3: iadd           // 将栈顶的两个数相加
4: istore_1       // 结果存入局部变量表
```

#### 1.2 `final` 在内存模型中的语义

根据 Java 内存模型（JMM），`final` 变量有两项重要的保障：
1. **构造器中对 `final` 变量的赋值操作不会与构造器内部的其他操作发生重排序**。这意味着，当一个对象的构造方法结束后，`final` 字段已经被正确初始化，其他线程访问到这个对象时，`final` 字段一定是已初始化的最终值。
  
2. **对象引用的“安全发布”**：当一个对象构造完成后（即构造函数结束），并且引用被发布出去时，其他线程在访问该对象时能够确保看到 `final` 字段的最新值。

举例：

```java
public class FinalExample {
    private final int x;

    public FinalExample(int x) {
        this.x = x;
    }

    public int getX() {
        return x;
    }
}
```

在多线程环境中，`FinalExample` 的 `x` 字段是 `final` 的，因此在对象构造完成后，所有线程都可以确保读取到正确的 `x` 值。这是因为 JMM 确保了构造器内部的重排序规则。

#### 1.3 `final` 与内存屏障

为了实现上述的内存语义，JVM 会在字节码层面使用 **内存屏障**（Memory Barrier）来防止对 `final` 变量的赋值和对象引用发布操作之间的重排序。

- **在构造器结束时**：JVM 会在 `final` 变量的赋值后插入 **StoreStore barrier**，确保该变量的赋值不会被重排序到其他操作之前。
  
- **在读 `final` 变量时**：JVM 在读取 `final` 变量之前插入 **LoadLoad barrier**，确保 `final` 变量的读取发生在对象引用被获取之后。

### 2. `final` 修饰方法的底层机制

`final` 方法意味着这个方法不能被子类重写。这个限制不仅仅是设计层面的，同时也给 JVM 提供了进行 **方法内联** 优化的机会。

#### 2.1 方法内联

在运行时，JVM 会对频繁调用的方法进行内联优化。所谓 **内联**，是指 JVM 将被调用的方法直接插入到调用处，避免方法调用的额外开销（如方法栈帧的创建和跳转等）。`final` 方法由于不能被重写，JVM 可以确保方法的唯一性，从而增加内联的机会。

**字节码指令**：

对于 `final` 方法调用，JVM 使用的指令是 `invokespecial`，而不是用于虚方法调用的 `invokevirtual`，因为 `final` 方法没有多态性，不需要通过虚方法表查找其实现。

举例：
```java
public class A {
    public final void method() {
        System.out.println("Final method");
    }
}
```

编译后的字节码：

```java
0: getstatic     #2                  // 获取 System.out
3: ldc           #3                  // 将 "Final method" 入栈
5: invokevirtual #4                  // 调用 println 方法
8: return
```

`invokespecial` 直接调用了 `method`，跳过了虚方法表。

#### 2.2 `final` 方法的优化

在 `final` 方法的调用过程中，JVM 可以执行更多的优化，因为它知道方法不会被重写。例如：
- **跳过虚方法查找**：由于 `final` 方法是确定的，JVM 可以跳过虚方法表查找，直接调用其具体实现。
- **内联**：JVM 可以将 `final` 方法的代码直接内联到调用处，减少方法调用的开销。

### 3. `final` 修饰类的底层机制

当一个类被声明为 `final` 时，它不能被继承。这在底层通过以下方式体现：

#### 3.1 字节码表示

在字节码中，`final` 类的定义包含 `ACC_FINAL` 标志位，表示这个类是 `final` 的。

```java
public final class MyClass {
    // 类的代码
}
```

生成的字节码中会包含：

```java
// access flags 0x11
// final class MyClass
```

这个标志告诉 JVM，这个类不能被子类化。

#### 3.2 编译器和 JVM 的优化

`final` 类由于不能被继承，JVM 可以对其进行一系列的优化操作。例如，JVM 可以对该类的方法进行直接调用，而不需要考虑继承关系和多态性。这使得方法调用更加高效。

另外，`final` 类也更适合用作不可变类（immutable class），如 `String`、`Integer` 等核心类库。不可变类在多线程环境中非常安全，因而 `final` 是不可变类设计中的关键元素。

### 4. `final` 的字节码和 JVM 内存模型

#### 4.1 字节码指令

`final` 修饰的字段的字节码使用的是 `putfield` 指令，这个指令在构造器中被调用。`putfield` 用于为对象的字段赋值，但对于 `final` 字段，编译器只允许在构造函数中使用 `putfield`，在其他地方修改 `final` 字段会导致编译错误。

例如：
```java
public class Test {
    private final int x;

    public Test(int x) {
        this.x = x;
    }
}
```

编译后的字节码：

```java
0: aload_0
1: iload_1
2: putfield      #2 // Field Test.x:I
5: return
```

#### 4.2 JVM 对 `final` 字段的内存语义

如前所述，`final` 字段在构造器中的赋值顺序不会与其他代码重排序，JVM 在构造函数中对 `final` 字段的赋值后，会插入内存屏障，确保 `final` 字段在其他线程访问时能看到正确的值。

总结来说：
- **`final` 提供了内存可见性保证**：在构造器中对 `final` 字段的赋值操作不会与其他操作重排序。
- **方法内联优化**：JVM 可以更好地内联 `final` 方法，避免虚方法调用的开销。
- **`final` 类的安全性**：`final` 类可以防止子类破坏其设计，尤其适用于不可变类的设计。

### 5. 总结

- **`final` 修饰字段**：字段在初始化后不可改变，编译器会进行常量折叠优化，并且提供线程安全的内存语义。
- **`final` 修饰方法**：方法不能被重写，JVM 可以进行内联优化，直接调用，提高性能。
- **`final` 修饰类**：类不能被继承，JVM 可以跳过多态检查，提升方法调用效率。

通过 `final` 的使用，Java 提供了更强的不可变性、安全性和优化机会，同时在底层通过内存屏障等机制，保障了多线程环境下的内存可见性和指令顺序的正确性。

### 虚方法表（Virtual Method Table，VMT）

**虚方法表**是用于实现面向对象编程语言（如Java、C++）中 **动态绑定**（又称为多态）的核心机制之一。通过虚方法表，JVM 能够在运行时确定要调用的具体方法，实现了继承与多态的动态分派。

#### 1. 为什么需要虚方法表？

在面向对象编程中，子类可以继承父类并重写父类的方法。这种重写意味着在编译时并不知道哪个类的方法会被调用。只有在运行时，根据具体的对象类型，才能确定具体要调用哪个方法。为了解决这种动态绑定的问题，虚方法表应运而生。

#### 2. 虚方法表的工作原理

当一个类被编译时，JVM 会为该类生成一个 **虚方法表**（VMT），这个表中存储了该类的所有 **虚方法** 的指针。虚方法是那些可以被子类重写的非 `private` 和非 `final` 的方法。

虚方法表的机制可以分为两部分：
1. **类加载时创建虚方法表**：当类加载器加载一个类时，它会为该类创建一个虚方法表。表中会包含父类方法的引用，如果子类重写了父类的方法，那么子类的虚方法表中相应位置会替换成子类方法的地址。

2. **实例对象持有指向虚方法表的引用**：每个类的实例对象都会持有一个指向该类虚方法表的引用（通常是一个隐含的指针）。当在对象上调用一个方法时，JVM 会通过这个指针找到对应的虚方法表，然后从表中查找到实际需要调用的方法地址。

#### 3. 虚方法表的结构

虚方法表可以看作是一个指针数组，每一个数组项都指向类中具体的虚方法。以下是简单的示意图：

```
Class A:
虚方法表 (VMT of Class A):
+--------------------+
| methodA() -&gt; A::methodA() |
| methodB() -&gt; A::methodB() |
+--------------------+

Class B extends A:
虚方法表 (VMT of Class B):
+--------------------+
| methodA() -&gt; B::methodA()  // 子类重写了方法
| methodB() -&gt; A::methodB()  // 子类未重写，指向父类实现
+--------------------+
```

假设有如下 Java 代码：

```java
class A {
    void methodA() {
        System.out.println("A::methodA");
    }

    void methodB() {
        System.out.println("A::methodB");
    }
}

class B extends A {
    @Override
    void methodA() {
        System.out.println("B::methodA");
    }
}
```

- 当类 `A` 被加载时，JVM 会为类 `A` 创建一个虚方法表，其中 `methodA` 和 `methodB` 指向 `A` 类的实现。
- 当类 `B` 被加载时，JVM 会为类 `B` 生成一个虚方法表，它继承自类 `A`。由于类 `B` 重写了 `methodA`，所以 `B` 的虚方法表中 `methodA` 的条目会指向 `B::methodA`，而 `methodB` 依旧指向 `A::methodB`。

当我们调用这些方法时：
```java
A obj = new B();
obj.methodA();  // 输出: B::methodA
```

即使 `obj` 的静态类型是 `A`，实际运行时调用的是 `B::methodA`，因为对象的动态类型是 `B`，JVM 会通过 `obj` 的虚方法表找到 `B` 的实现。

#### 4. 动态绑定的实现

在执行到一个对象方法调用时，JVM 通过以下几个步骤实现动态绑定：

1. **编译时的静态类型**：编译器知道对象的静态类型，并生成相应的字节码指令。
  
2. **运行时的动态分派**：当程序执行时，JVM 根据对象的实际类型查找虚方法表。通过该表中的指针，JVM 确定实际调用哪个方法。

3. **`invokevirtual` 指令**：在 Java 字节码中，调用虚方法的指令是 `invokevirtual`。这个指令告诉 JVM 去查找虚方法表来执行具体的方法调用。

```java
A obj = new B();
obj.methodA();
```

对应的字节码：
```bash
0: invokevirtual #2  // Method A.methodA:()V
```

这里的 `invokevirtual` 指令会告诉 JVM 进行虚方法查找。JVM 会通过 `obj` 对象找到其所属的类的虚方法表，并根据表中的指针找到实际的 `methodA()` 方法。

#### 5. 优化与性能考虑

虚方法表的使用避免了每次方法调用时都需要重新搜索类的继承层次结构，从而提升了方法调用的效率。对于多态方法调用，使用虚方法表的性能要远高于反射机制。

不过，虚方法调用依然比 `static` 方法或 `final` 方法的调用开销更大。这是因为 `static` 和 `final` 方法在编译时就确定了方法的调用地址，而虚方法需要依赖运行时的动态绑定。

### 6. 结论

虚方法表是实现 Java 多态的关键机制，它通过记录类中虚方法的地址，保证了在运行时动态调用正确的方法实现。通过虚方法表，JVM 可以有效地实现面向对象语言中的动态分派，而不必每次都遍历继承树来查找方法实现，这极大地提高了虚方法调用的效率。





## 内核线程模型

Java的线程模型基于操作系统的**内核线程模型**（Kernel Thread Model），即每个Java线程在底层都会映射到一个操作系统内核线程。这种模型由操作系统负责线程的调度、切换以及管理，程序本身不需要显式地处理线程的底层操作系统资源管理。为了理解Java的线程模型是内核线程模型，下面将详细介绍线程、内核线程模型及其在Java中的实现和特点。

```
### 1. 什么是线程

线程是操作系统调度执行的最小单位，它包含程序的执行逻辑和状态。在一个多线程环境中，多个线程可以并发执行，通常共享同一进程的内存空间，但每个线程有独立的堆栈、程序计数器和寄存器等。

线程可以分为三类：

- **用户线程**：在应用程序中由开发者显式创建和管理的线程。
- **内核线程**：由操作系统内核支持和调度的线程，负责真正执行任务。
- **轻量级线程**（LWP，Lightweight Process）：介于用户线程和内核线程之间，是用户线程与内核线程的中间接口，某些操作系统（如Solaris）支持。

### 2. 线程模型概述

线程模型主要有以下几种：

- **用户线程模型**（User Thread Model）：线程的管理完全由用户级别的线程库负责，而操作系统内核对其不可见。用户线程通过用户态调度来实现，但这种模型无法充分利用多核 CPU。

- **内核线程模型**（Kernel Thread Model）：每个线程直接由操作系统内核管理和调度。内核线程在系统中是独立的执行单位，操作系统会为每个线程分配 CPU 时间、进行上下文切换，并通过内核态执行调度。

- **混合线程模型**（Hybrid Thread Model）：结合用户线程和内核线程，用户线程通过轻量级线程与内核线程进行映射。

Java使用的是**内核线程模型**，它依赖操作系统的线程调度机制。每个Java线程在底层都由一个内核线程支持，并通过操作系统内核来进行线程调度和管理。

### 3. Java 线程模型是内核线程模型的原因

Java的线程模型依赖于底层的操作系统，它的线程实现与操作系统的线程模型密切相关。通常情况下，Java线程通过JVM调用操作系统的原生线程库来创建、管理和调度线程。

#### 3.1 线程的映射

Java线程在不同操作系统中的实现通常是**一对一映射**（1:1 Model），即一个Java线程对应一个内核线程。这种设计意味着Java线程的调度和执行完全依赖操作系统的内核线程，Java不需要自己处理线程的底层调度逻辑。操作系统负责所有Java线程的调度、上下文切换以及管理。

#### 3.2 操作系统线程调度

在内核线程模型下，所有线程的调度、创建、销毁以及执行管理都是由操作系统内核负责。操作系统会根据系统负载、线程优先级、时间片等规则为每个线程分配CPU时间片并进行上下文切换。

- **调度器**：操作系统的线程调度器负责决定何时以及如何切换线程，分配CPU资源给不同的线程。每个线程运行一段时间后会被调度器挂起，操作系统将CPU分配给其他线程执行。

- **上下文切换**：当线程被挂起并将CPU资源让给其他线程时，系统会保存当前线程的上下文（如寄存器、程序计数器等），当它重新获取CPU时，系统会恢复其上下文以继续执行。

#### 3.3 操作系统的线程管理

由于Java线程是映射到操作系统的内核线程，因此Java应用程序中的线程与操作系统的多核处理能力密切相关。现代操作系统支持多核处理器，每个核心可以并行运行一个线程。Java的线程模型通过操作系统的内核线程调度，使得Java应用程序能够充分利用多核 CPU 的性能，实现真正的并行处理。

在这种模型下，Java程序可以创建任意数量的线程，具体的调度和管理由操作系统内核负责。操作系统会对这些线程进行调度，将它们分配到CPU核心上并行执行。

#### 3.4 平台相关的实现

Java线程依赖于不同操作系统的原生线程库，因此不同平台上的Java线程模型略有不同。例如：

- **Linux** 使用 `pthread` 实现多线程。Java线程通过JVM调用 `pthread` 接口创建和管理线程。
- **Windows** 使用 `CreateThread` 函数创建内核线程，JVM通过调用Windows API来管理线程。

每个操作系统的原生线程库实现了Java线程的管理功能，Java不需要重新实现线程的底层管理逻辑。

### 4. Java 内核线程模型的优缺点

#### 4.1 优点

- **充分利用多核处理器**：Java线程是通过内核线程实现的，操作系统能够在多个CPU核心上并行调度线程，Java程序可以充分利用多核处理器的性能。

- **线程独立性**：每个线程是独立的，由操作系统管理，因此一个线程的阻塞不会影响其他线程的执行。这对于构建可靠的并发应用非常有帮助。

- **操作系统层面的优化**：现代操作系统的内核线程调度机制非常高效，支持优先级调度、实时调度等功能，Java程序可以直接利用操作系统的调度优化。

#### 4.2 缺点

- **上下文切换开销大**：每次线程的上下文切换都需要保存和恢复CPU的寄存器、程序计数器等，导致一定的开销。在高并发环境下，频繁的上下文切换可能会降低性能。

- **内核资源开销大**：每个内核线程都需要占用一定的系统资源（如内存、文件描述符等）。当Java程序创建大量线程时，可能会导致系统资源耗尽。

- **线程创建销毁成本高**：由于线程的创建和销毁需要操作系统内核的参与，Java线程的创建和销毁比用户级线程模型开销更大。因此，在高并发场景下，频繁创建和销毁线程可能会影响系统性能。

### 5. Java 中的线程调度与内核线程模型

在Java中，线程调度由操作系统完成，JVM 不会直接参与线程的调度决策。JVM 通过调用操作系统的线程管理API来创建和管理线程，具体的调度和执行顺序则完全依赖于操作系统的调度器。

- **时间片轮转调度（Round-robin Scheduling）**：许多操作系统使用时间片轮转调度算法，每个线程分配固定的时间片执行，当时间片耗尽时，系统切换到下一个线程。

- **优先级调度**：在Java中，线程有优先级（Priority），操作系统通常会优先调度高优先级的线程执行。但是优先级调度依赖操作系统，有些系统可能忽略线程优先级，只使用时间片调度。

- **阻塞与唤醒**：当线程等待资源或进入阻塞状态时，操作系统会将其调度出CPU。当资源可用或被唤醒时，操作系统再将其重新调度到CPU上继续执行。

### 6. Java 的并发模型与线程池

为了减少频繁创建和销毁线程的开销，Java 提供了**线程池**机制。通过线程池，可以在程序启动时创建一组固定数量的线程，并在整个程序运行过程中重复使用这些线程，减少了线程创建和销毁的开销，同时也减少了内核线程模型中频繁的上下文切换问题。

Java中最常用的线程池实现是通过 `java.util.concurrent.ExecutorService` 接口实现的，典型的线程池类型有：

- **固定大小线程池（FixedThreadPool）**：创建固定数量的线程池。
- **缓存线程池（CachedThreadPool）**：线程池可以动态扩展或收缩。
- **调度线程池（ScheduledThreadPool）**：支持定时任务或周期性任务调度。

### 7. Java Loom 项目与轻量级线程

为了进一步优化线程的资源消耗和管理，Java 正在开发 **Loom 项目**，目标是引入 **虚拟线程**（Virtual Thread）。虚拟线程不再依赖操作系统内核线程，而是由JVM管理调度。虚拟线程将消耗更少的资源，且具有更轻量的线程上下文切换机制。Loom 项目将使Java可以支持更多数量的并发线程，从而进一步提高高并发场景下的性能。

---

### 总结

Java的线程模型是基于操作系统的**内核线程模型**，每个Java线程直接映射到一个操作系统的内核线程。操作系统负责线程的调度、管理、创建和销毁。虽然这种模型在多核处理器环境下能够充分利用操作系统的多核并行能力，但线程的上下文切换和资源消耗较大。在高并发场景中，Java通过引入线程池等机制减少线程的创建和销毁开销，优化了性能。而未来的 **Loom 项目** 通过引入轻量级线程（虚拟线程）将进一步提高Java在并发编程中的效率。

Java程序确实运行在**用户态**（user mode），但是当涉及到线程调度、IO操作（如网络通信、文件读写）等系统级操作时，Java程序需要通过操作系统内核提供的系统调用（system call）来完成这些任务。这就意味着，**Java程序在某些情况下确实需要进行用户态到内核态的切换**。下面我将详细解释这个过程，以及为什么Java程序通常还是运行在用户态的。
```



```
### 1. 什么是用户态和内核态？

计算机操作系统通常分为两种运行模式：

- **用户态（user mode）**：用户态是应用程序（如Java程序）运行的地方，应用程序的执行权限受到限制，不能直接访问硬件设备或操作系统的核心资源。当应用程序需要访问这些资源时，必须通过操作系统提供的接口进行。

- **内核态（kernel mode）**：内核态是操作系统核心部分运行的地方，具有完全的权限来访问硬件设备、管理内存、调度线程、处理IO等。内核态的代码可以直接与硬件交互。

应用程序在用户态运行时，如果需要执行与硬件相关的操作，必须通过系统调用进入内核态，由操作系统内核执行相应的操作。

### 2. Java程序运行在用户态

Java程序通常在用户态运行，这意味着Java代码本身不能直接访问硬件或操作系统资源，而是通过JVM（Java虚拟机）运行在用户态中。JVM本身也是一个用户态程序，它执行Java字节码，并为Java应用程序提供运行环境。大部分Java程序执行的操作，比如计算、对象创建等，都在用户态下进行，**不涉及用户态到内核态的切换**。

### 3. 用户态到内核态的切换场景

虽然Java程序大部分时间运行在用户态，但当它需要与操作系统交互时，用户态到内核态的切换是不可避免的。以下是一些Java程序会触发用户态到内核态切换的常见场景：

#### 3.1 **线程调度**

Java使用的线程模型是基于操作系统的内核线程（Kernel Threads），每个Java线程对应一个内核线程。**线程的创建、调度、销毁等操作都由操作系统内核管理**，因此当Java程序创建或调度线程时，需要进行系统调用，这会触发用户态到内核态的切换。

- 例如，Java程序调用 `Thread.start()` 启动一个新线程时，JVM 通过系统调用请求操作系统创建一个新的内核线程，期间发生用户态到内核态的切换。
- 当操作系统在调度线程时，也会涉及内核态调度机制，并通过上下文切换来管理线程执行。

#### 3.2 **IO操作（文件读写、网络通信等）**

Java程序中的所有IO操作都会涉及系统调用，进而触发用户态到内核态的切换。无论是读取文件、写入数据、网络通信，Java都依赖操作系统的IO子系统来与硬件进行交互。

- 例如，Java中的 `FileInputStream` 和 `Socket` 操作最终都要通过系统调用访问底层的文件系统或网络接口。每次文件读写或者网络操作时，Java程序必须通过操作系统内核调用来执行这些操作。

IO操作通常比较耗时，因此Java常使用异步IO、NIO（New IO）等技术来减少阻塞，通过减少频繁的用户态到内核态切换来提高性能。

#### 3.3 **内存管理（虚拟内存、堆栈管理等）**

虽然Java程序的内存分配（如对象分配）通常由JVM的垃圾回收器（Garbage Collector, GC）管理，但底层的内存管理依然依赖操作系统。比如，当Java程序需要更多内存时，JVM会向操作系统请求分配内存，这也需要系统调用，导致用户态到内核态的切换。

- 例如，操作系统使用虚拟内存管理，当Java程序申请一大块内存（如堆区内存增长）时，可能需要通过 `mmap` 或 `brk` 等系统调用从操作系统获取内存。

此外，当垃圾回收器在进行内存清理时，可能涉及内存页的调度或回收操作，部分操作会涉及内核态的资源管理。

#### 3.4 **进程管理**

Java中的 `Runtime.exec()` 或 `ProcessBuilder` 可以启动一个新的操作系统进程，这个操作需要调用操作系统的进程创建函数（如 `fork()` 或 `execve()`），这也会导致用户态到内核态的切换。

#### 3.5 **锁与同步原语**

Java中的锁和同步机制（如 `synchronized` 和 `Lock`）有时也会触发内核态切换。大多数简单的锁操作可能在用户态下完成，但当线程竞争激烈时，可能需要依赖操作系统提供的互斥量（Mutex）或信号量（Semaphore）等原语来协调线程，这时会发生用户态到内核态的切换。

### 4. 用户态和内核态切换的开销

用户态到内核态的切换是有代价的，主要体现在以下几个方面：

- **上下文切换成本**：从用户态切换到内核态时，需要保存当前执行线程的上下文（包括寄存器、程序计数器等），并切换到内核态执行代码。每次上下文切换都会引入额外的时间开销。

- **CPU模式切换**：切换到内核态时，CPU的运行模式从用户模式转为内核模式，这个过程需要硬件支持并耗费一定的资源。

- **性能损失**：如果系统调用或IO操作频繁，用户态和内核态之间的频繁切换会导致性能下降，尤其在高并发场景中，切换的开销会更加明显。

为此，许多优化技术（如零拷贝技术、异步IO、批处理操作等）被提出，以减少用户态到内核态的切换次数，提升整体性能。

### 5. Java 线程池和异步IO对用户态到内核态切换的优化

Java 提供了一些优化机制，尽量减少不必要的用户态到内核态切换：

#### 5.1 **线程池**

Java的线程池通过复用线程减少了频繁的线程创建和销毁操作，从而减少了系统调用的开销。通过复用已经存在的线程，线程池避免了反复切换到内核态来创建新线程的开销。

#### 5.2 **异步IO**

Java中的 **NIO**（New IO）和 **AIO**（Asynchronous IO）通过异步模型允许程序在等待IO操作时不阻塞线程，减少了同步阻塞引发的频繁内核态切换问题。在异步IO模型中，Java程序可以在用户态等待IO完成，而不需要反复切换到内核态进行查询（轮询）。

例如，使用 `Selector` 和 `Channel` 实现非阻塞IO操作时，可以避免大量的线程阻塞在IO上，从而减少了不必要的线程调度和用户态到内核态的切换。

### 6. 虚拟线程（Project Loom）的改进

Java社区正在通过**Project Loom**引入**虚拟线程（Virtual Threads）**，旨在进一步优化Java线程的并发模型。虚拟线程不依赖操作系统的内核线程，而是由JVM本身管理。这样可以避免频繁的内核线程创建、销毁以及上下文切换的开销。

虚拟线程的设计目标是提供一个更加轻量级的并发模型，使得Java程序可以拥有更多的线程而不会因为操作系统的限制而导致性能下降。虽然虚拟线程的执行依然需要涉及某些操作的用户态到内核态切换（如IO操作），但大量线程的调度和管理将由JVM完成，避免了频繁依赖操作系统的线程管理机制。

### 总结

虽然Java程序本质上运行在用户态，但当Java程序需要执行系统级任务（如线程管理、IO操作、进程创建、内存分配等）时，必须依赖操作系统内核的支持。这些任务通过系统调用的方式触发用户态到内核态的切换，这种切换带来了性能开销。因此，在Java的高并发编程中，如何减少不必要的用户态到内核态切换成为优化性能的重要课题。

通过使用线程池、异步IO、NIO等机制，可以减少这些切换的频率，提升程序性能。而未来通过虚拟线程，Java将进一步降低对内核线程的依赖，优化线程管理带来的开销。
```



```
用户线程模型（User Thread Model）是指线程的创建、管理和调度完全由用户态的线程库负责，操作系统内核对这些线程是不可见的。每个用户线程都运行在用户态中，操作系统认为它们是单一的进程，并不会识别这些线程。因此，用户线程无法充分利用多核CPU的并行处理能力，原因可以总结为以下几点：

### 1. 操作系统只识别进程，不识别用户线程

在用户线程模型中，操作系统认为用户线程所在的整个进程是一个单独的执行单元。用户线程的管理和调度全部由用户态的线程库完成，而操作系统内核不会感知到用户线程的存在。具体来说：
- **单个进程对应单个内核线程**：操作系统只给进程分配一个内核线程，操作系统层面看到的仍然是一个单一的进程，而不是多个线程。
- **多线程在用户态进行调度**：虽然应用程序中存在多个用户线程，但它们的调度是在用户态内完成的，由用户线程库负责。这种调度在操作系统看来是透明的，操作系统无法识别并独立调度每个用户线程。

由于操作系统无法感知和管理用户线程，因此即使系统有多个CPU核心，操作系统也只会为该进程分配一个CPU核心来执行。所有的用户线程都在这个单一的核心上被调度和执行，从而无法利用其他的CPU核心进行并行处理。

### 2. 用户态线程调度与内核态调度脱钩

在用户线程模型中，线程的调度完全由用户态线程库管理，与操作系统内核的线程调度机制无关。这导致了几个问题：

- **用户态线程的调度器无法影响内核态调度器**：操作系统的内核调度器只负责调度内核线程，而用户线程库的调度器则负责调度用户线程。这意味着操作系统内核无法参与或优化这些用户线程的调度，操作系统仍然认为只有一个进程在运行。

- **用户线程的并行性依赖于操作系统分配的核心数量**：由于操作系统只给进程分配一个核心来执行，所以用户态线程之间实际上是通过时间片轮转在一个核心上切换执行的，而不是并行执行的。即使程序有多个用户线程，它们也只是顺序地在单一核心上执行，无法利用多核CPU的并行计算能力。

- **用户态线程调度器的局限性**：由于用户态线程调度器没有访问底层硬件资源（如多核CPU）的权限，它无法直接将多个线程分配到多个CPU核心上。线程库只能在单个核心上轮换执行用户线程，无法将线程分布到多个核心上并行处理。

### 3. 阻塞操作导致全局阻塞

另一个问题是，当用户线程进行系统调用（如I/O操作）时，整个进程可能会被阻塞：
- **内核无法感知到用户线程的阻塞**：在用户线程模型中，如果一个用户线程发起了阻塞系统调用（如文件IO操作、网络请求），整个进程都会被阻塞。这是因为在用户线程模型中，所有用户线程共享同一个内核线程，如果该内核线程被阻塞，操作系统无法调度其他用户线程来运行。
  
- **单核执行阻塞用户线程**：由于操作系统只分配了一个核心给进程，即使其他CPU核心是空闲的，操作系统也无法将其他用户线程调度到其他核心上继续执行。这意味着如果一个用户线程被阻塞，整个进程可能都会进入等待状态，浪费了多核CPU的计算资源。

### 4. 上下文切换的局限性

在内核线程模型中，操作系统的内核负责线程的调度和上下文切换，操作系统可以利用多核CPU，保证线程在多个核心上并行运行。然而，用户线程模型的调度完全由用户态线程库控制，这带来了一些局限性：
- **用户态线程切换效率低**：虽然在用户态切换线程可能比在内核态切换线程开销小（不需要内核的参与），但这种切换是发生在同一个CPU核心上的，没有利用多个CPU核心的机会。因此，用户态线程模型中的上下文切换只是在一个CPU核心之间轮转。
  
- **无法并发执行**：用户线程无法在多个核心上同时运行，所有的线程上下文切换都发生在同一个CPU核心上。虽然理论上用户态线程调度的开销较小，但由于缺乏多核并行执行的能力，性能仍然受到限制。

### 5. 用户线程模型的特定应用场景

虽然用户线程模型无法充分利用多核CPU，但它在某些特定场景中依然具有一定的优势，特别是那些不需要大量并行计算、对并行度要求较低的场景：
- **轻量级调度**：用户线程的调度在用户态进行，减少了系统调用和内核态上下文切换的开销，线程切换开销相对较小。
- **不依赖内核线程**：由于用户线程不依赖操作系统内核的调度，开发者可以更加灵活地实现自定义的线程调度策略。

用户线程模型在一些特殊的场景下依然有用，比如某些嵌入式系统或资源受限的环境中，内核线程的开销太大，而应用程序的并发需求较低时，用户线程模型依然能够提供足够的并发能力。

### 6. 对比内核线程模型

相对用户线程模型，**内核线程模型**（如Java的线程模型）将每个用户线程映射到一个操作系统内核线程。操作系统的内核调度器可以将不同的线程分配到不同的CPU核心上并行执行，充分利用多核CPU的优势：
- **多核并行**：内核线程模型可以让多个线程同时在多个核心上执行，这样多个线程可以并行处理，提高了程序的整体性能。
- **阻塞隔离**：在内核线程模型中，如果一个线程阻塞，其他线程依然可以继续执行，不会影响整个进程的并行性。
  
因此，内核线程模型更适合需要高并发和多核利用的场景，如服务器应用、大型计算任务等。

### 7. 混合线程模型（Hybrid Thread Model）

为了弥补用户线程模型的不足，一些系统实现了**混合线程模型**，如 **1:N** 或 **M:N** 模型：
- **1:N 模型**：多个用户线程映射到一个内核线程上，这个模型类似于纯用户线程模型，无法利用多核。
- **M:N 模型**：多个用户线程通过多个内核线程进行调度，即 `M` 个用户线程可以映射到 `N` 个内核线程上，这样可以通过多个内核线程来同时在多个CPU核心上执行部分用户线程，从而达到一定的并行性。

混合线程模型的目的是在保留用户态线程管理灵活性的同时，部分引入内核线程模型的并行能力，以利用多核CPU的优势。

---

### 总结

**用户线程模型无法利用多核CPU的根本原因在于操作系统内核无法感知用户态的线程调度**。在这种模型中，操作系统认为进程是单一的执行单元，只分配一个CPU核心给该进程执行。由于所有线程调度在用户态完成，无法利用操作系统的多核并行调度功能，所有用户线程只能在一个核心上轮转执行。因此，用户线程模型无法有效利用多核CPU进行真正的并行计算。

相比之下，内核线程模型能够充分利用多核CPU，因为操作系统负责线程调度，可以将不同的线程分配到不同的核心上并行执行，提升了并发性能和多核利用率。
```

