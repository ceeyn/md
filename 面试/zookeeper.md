



Zookeeper面试题

https://blog.csdn.net/wanghaiping1993/article/details/125396988?ops_request_misc=%257B%2522request%255Fid%2522%253A%25222DF40C04-E0BD-43FA-976F-BADB1C3F2590%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=2DF40C04-E0BD-43FA-976F-BADB1C3F2590&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-19-125396988-null-null.142^v100^pc_search_result_base8&utm_term=ZooKeeper&spm=1018.2226.3001.4187



https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg%3D%3D&chksm=f36beb7ec41c6268df9ac795636b8ec7a831a2a4776b84499055cfcbc2bb2834b124e1e8b8c5&idx=3&mid=2650142303&scene=27&sn=dbaba0ef4dba03d7dc97bdd08d03ac57&utm_campaign=geek_search&utm_content=geek_search&utm_medium=geek_search&utm_source=geek_search&utm_term=geek_search#wechat_redirect

# ZAB

<img src="/Users/moon/Library/Application Support/typora-user-images/image-20241216163711784.png" alt="image-20241216163711784" style="zoom: 33%;" />

### 1.崩溃恢复

每个节点投给自己，然后广播投票，收到投票后重新更新选票，投票内容为（id，zxid）



### 2.原子广播

leader 维护两种队列，第一种保存每个folloer 的最后一个 zxid，为了维持线性一致性，第二种是 observer 的



## 1. 崩溃恢复阶段（选主）

这部分描述的是 ZooKeeper 中 **Leader 选举** 的过程，发生在：

- 节点崩溃后重启
- 集群刚刚启动
- Leader 挂掉后重新选主

### 🧠 流程简述：

> **每个节点（Server）投给自己，然后广播选票**
>  选票内容通常包括：

```
复制编辑
<VotedForId, VotedZxid, Epoch>
```

| 字段    | 含义说明                                      |
| ------- | --------------------------------------------- |
| `id`    | 当前认为的 Leader ID                          |
| `zxid`  | 当前节点的事务 ID（ZooKeeper Transaction ID） |
| `epoch` | 选举轮数（逻辑时钟）                          |

### ✅ 投票规则：

每个节点会根据投票规则选出「看起来最先进」的节点作为 Leader 候选：

> 谁的 `epoch` 更大，优先
>  如果相同，再比 `zxid`
>  如果再相同，再比 server id（节点 id）

最终，收到超过半数投票时，成为 Leader。

------

## ✅ 2. 原子广播阶段（Zab 协议）

ZooKeeper 选出 Leader 后，进入 **原子广播阶段**，用于分布式一致性写入。

你提到的：

> “Leader 维护两种队列，一种保存 follower 的 zxid，为了线性一致性，另一种是 observer 的队列”

我们来详细讲解 👇

------

### ✅ Leader 维护的两种队列：

------

### **（1）Follower ACK 队列（核心）**

- Leader 会把每条事务（Proposal）广播给所有 follower（参与投票的节点）
- 每个 follower 收到后返回 ACK（确认）
- Leader 只有在 **收到超过半数的 ACK 后，才会提交（commit）这条事务**

#### ✨ 特点：

- 保证了 **线性一致性**【只有leader可以进行写操作，没有选出leader的时候写操作不可用】
- 所有 follower 都执行相同的事务、顺序一致
- 这就是 ZooKeeper 的「原子广播」

------

### **（2）Observer 队列（只读节点）**

- Observer 是只读节点，不参与投票和选举
- 接收来自 Leader 的事务通知，但不会返回 ACK
- Leader 维护一个单独的 Observer 通知队列，**只用于同步数据**

#### ✨ 特点：

- Observer 不影响一致性
- 可横向扩展集群的读能力

------

## 🔄 整体流程梳理一下：

1. **Leader 收到客户端写请求**
2. 将事务包装为 Proposal（带 zxid），广播给所有 follower
3. 收到半数以上 follower 的 ACK
4. Leader 执行 commit，通知所有 follower 和 observer 提交
5. 客户端收到写入成功响应

------

## 线性一致性

```
你对 ZooKeeper 做两次写操作：

plaintext
复制
编辑
Client A: set /node1 = "X"
Client B: get /node1
如果是线性一致性，B 一定能看到 "X"。

即使 A 和 B 是不同机器发起的、请求顺序非常近，只要 B 是在 A 之后发的，就必须看到最新的值，不能看到旧值。


```

### 关键点：**ZooKeeper 所有写请求都必须由 Leader 来处理！**

- Follower 节点不能接收写请求
- 所有写操作都通过 Leader 发起原子广播（Zab）
- 没有 Leader，就**没有办法确保线性一致性**



## 同步是follower发送最后一个zxid来进行的

### ✅ 步骤 1：Follower 连接 Leader，发送自己的最新事务 ID（lastZxid）

每个 Follower 本地会保存它执行过的最后一个事务的编号（`lastZxid`），例如：

```
plaintext


复制编辑
Follower A 的 lastZxid = 0x300000004 （第3代 Leader，操作序号=4）
```

它会在启动时向 Leader 发送一个包含该值的 `FOLLOWERINFO` 包。

------

### ✅ 步骤 2：Leader 对比自己的事务日志

Leader 收到 Follower 的 lastZxid 后，会对比：

- 自己当前最新事务的 zxid（比如 0x300000007）
- 和 Follower 提供的 zxid（0x300000004）

发现：Follower 只缺少 `zxid = 0x300000005 ~ 0x300000007` 这三条事务。

```
Follower           Leader
  zxid=4           zxid=7
    │                │
    └─ FOLLOWERINFO  ───▶ 发送 4
                      │
             Leader 知道你差了 5~7
                      │
    ◀─ Proposal(5) ◀───
    ◀─ Proposal(6) ◀───
    ◀─ Proposal(7) ◀───

```





### 3. **总结对比**

| 特性                 | **ZooKeeper**                                  | **Nginx**                                      |
| -------------------- | ---------------------------------------------- | ---------------------------------------------- |
| **单点故障**         | 无单点故障，通过 ZAB 协议保证高可用性          | 存在单点故障，需要通过 KeepAlived 实现高可用性 |
| **高可用性实现方式** | 通过 Quorum 机制和 Leader 选举保证高可用性     | 使用 KeepAlived 或 LVS 进行故障切换和负载均衡  |
| **故障处理机制**     | Leader 宕机时自动选举新的 Leader，无需手动干预 | 通过 VIP 实现主备切换，备用节点接管流量        |
| **优点**             | 不存在流量中断，选举过程快速稳定               | 通过多个节点实现流量切换，保证服务不中断       |
| **适用场景**         | 分布式系统中的协调服务                         | 流量调度、反向代理和负载均衡                   |

### 4. **进一步扩展**

ZooKeeper 通过分布式共识算法（如 ZAB 协议）来实现强一致性和高可用性，而 Nginx 主要依赖高可用性工具（如 KeepAlived）来保证服务不中断。对于需要大规模服务协调的分布式系统，ZooKeeper 能够提供无单点故障的高可用架构。而在 Web 应用和流量调度场景下，Nginx 通过 KeepAlived 这样的工具能够有效解决单点问题，实现高可用的反向代理和负载均衡。



https://blog.csdn.net/kangbin825/article/details/140008963

Eureka 是 Netflix 开源的分布式服务注册与发现框架，主要用于微服务架构中解决服务的动态注册和发现问题。下面我会详细解释 Eureka 的特点、工作原理以及设计理念，重点突出其与 CAP 原则的关系，以及如何通过自我保护机制等特性来实现高可用性。

### 1. **Eureka 的特点**

#### 1.1 **可用性（AP 原则）**
- **CAP 原则** 中的三种属性分别是：**一致性（C: Consistency）**，**可用性（A: Availability）** 和 **分区容忍性（P: Partition Tolerance）**。根据 CAP 原则，在分布式系统中，无法同时完全保证一致性、可用性和分区容忍性，因此必须在三者之间做出权衡。
- **Eureka** 在设计时遵循了 **AP 原则**，即 **可用性和分区容忍性优先**，而牺牲了一部分一致性。这意味着：
  - **Eureka** 确保即使某些节点不可用，服务注册中心仍然能对外提供服务，保证系统的高可用性。
  - 但是，服务的注册信息可能不是最实时的，可能存在短暂的数据不一致性。

#### 1.2 **去中心化架构**
- Eureka 的架构是 **去中心化** 的，采用了 **Peer to Peer 对等通信** 的模式，而不是像 ZooKeeper 那样的主从（Master-Slave）结构。所有 Eureka Server 实例都是对等的，没有 Leader 和 Follower 的区别。
- 这种设计使得 **Eureka** 更加灵活，能够避免单点故障的问题。每个 Eureka Server 节点都可以独立工作，即使某些节点宕机，其他节点仍然可以继续提供服务。

#### 1.3 **请求自动切换**
- 当一个 **Eureka Server** 节点宕机时，Eureka Client 可以自动切换到其他可用的 Eureka Server 节点继续工作。Eureka Client 会定期刷新注册信息，并且维护多个 Eureka Server 地址，当宕机的节点恢复后，Client 会重新将其纳入到服务发现的流程中。
- 这种自动切换机制保证了注册中心的高可用性，避免了因为某个节点宕机而导致服务发现的中断。

#### 1.4 **节点间的操作复制**
- 当一个 Eureka Server 接收到客户端的服务注册或注销请求时，它会将这个操作复制到集群中其他所有 Eureka Server 节点。这确保了集群中每个 Eureka Server 的注册信息保持一致（尽管复制过程存在一定的延迟）。
- 这种操作复制机制保证了注册信息的冗余存储，避免了单点故障的风险。

#### 1.5 **自动注册和心跳**
- Eureka Client 在启动时会自动向 Eureka Server 注册服务，并且每隔 30 秒发送一次心跳，告知 Eureka Server 自己的健康状态。
- 如果 Eureka Server 在 90 秒内没有接收到某个服务实例的心跳，它将认为该实例不可用，并将其从注册表中删除。

#### 1.6 **自我保护模式**
- **自我保护模式** 是 Eureka 为了提高可用性而设计的一个容错机制。
  - 当 Eureka Server 发现大量 Eureka Client 的心跳在短时间内消失（例如网络分区时），它会进入自我保护模式。
  - 在自我保护模式下，Eureka 不会主动删除没有发送心跳的服务实例，而是继续允许这些实例提供服务。这种机制避免了由于网络问题导致的服务过早下线。
  - 一旦网络恢复，Eureka 会自动退出自我保护模式，重新进行注册表的同步。

#### 1.7 **保护模式细节**
- **保护模式** 主要处理网络抖动或大规模网络问题。Eureka 通过统计短时间内心跳丢失的比例（默认是 15 分钟内超过 85% 的心跳丢失）来判断是否需要进入自我保护模式。
  - 当检测到大量的客户端心跳丢失时，Eureka 不会删除这些服务实例的信息，仍然允许其他服务继续进行注册和查询，但新的注册信息不会立即同步到其他节点。【防止因网络不稳定导致数据混乱或丢失。】
  - 这样做的好处是，即使在出现网络异常的情况下，Eureka 仍然可以为客户端提供服务，保证了系统的高可用性。

### 2. **Eureka 工作原理**

Eureka 的核心工作流程如下：

1. **Eureka Server 启动**
   - 当 Eureka Server 启动后，它会通过集群中的其他 Eureka Server 同步服务注册表，确保自己拥有完整的注册表信息。如果是独立的 Server，它会等待服务端的注册。
   
2. **Eureka Client 注册**
   - Eureka Client 在启动时，会根据配置的 Eureka Server 地址，将自身的服务信息注册到 Eureka Server 中。
   - 客户端会周期性地发送 **心跳请求**（默认 30 秒），以确保自己处于健康状态。

3. **心跳检测与实例注销**
   - 如果 Eureka Server 在 90 秒内没有收到某个服务实例的心跳，它会认为该实例不可用，并将其从注册表中删除。
   
4. **自我保护机制**
   - 当 Eureka Server 在短时间内丢失了大量的心跳时，它会进入自我保护模式，保持已注册的服务实例，而不会立即将其移除。这种机制保证了在网络抖动或分区情况下的高可用性。
   
5. **服务调用**
   - 当某个服务需要调用另一个服务时，它会首先从本地缓存中获取服务信息。如果缓存中没有，则会向 Eureka Server 请求最新的服务注册表。
   - 客户端会周期性地从 Eureka Server 拉取最新的服务注册表，以保持缓存中的服务信息与注册中心一致。
   
6. **服务注销**
   - 当客户端关闭时，它会向 Eureka Server 发送一个取消注册的请求，Eureka Server 将该实例从注册表中删除。

### 3. **Eureka 的优势**

#### 3.1 **高可用性**
- 通过去中心化的架构和 Peer to Peer 对等通信机制，Eureka 可以避免单点故障，并通过自动切换机制保证集群中任意一个节点宕机时，客户端依然能够找到其他节点继续工作。

#### 3.2 **可扩展性**
- 由于每个 Eureka Server 都是对等的，因此 Eureka 的集群可以通过添加更多的 Server 实例来实现水平扩展，增强系统的可用性和容错能力。

#### 3.3 **自我保护机制**
- 自我保护模式使得 Eureka 能够容忍临时的网络故障，避免因短暂的网络问题导致大量服务实例被错误地移除，保证了服务注册中心的可用性。

#### 3.4 **适合跨机房部署**
- Eureka 设计上不追求强一致性，而是保证了高可用性和分区容忍性。因此，它非常适合部署在跨多个机房的环境中，即使机房间的网络出现问题，也能保证服务注册中心的可用性。

### 4. **Eureka 和 ZooKeeper 的区别**

#### 4.1 **一致性 vs 可用性**
- **ZooKeeper**：更强调 **一致性**，使用的是 CP 模型（Consistency 和 Partition Tolerance）。在 ZooKeeper 中，网络分区会导致选举 Leader，期间服务可能无法处理请求，这样可以确保系统的数据一致性。
- **Eureka**：更强调 **可用性**，使用的是 AP 模型（Availability 和 Partition Tolerance）。Eureka 通过牺牲数据一致性，来保证注册中心在网络分区等异常情况下仍然可以对外提供服务。

#### 4.2 **中心化 vs 去中心化**
- **ZooKeeper** 依赖于中心化的 Leader-Follower 架构，Leader 负责所有写操作。
- **Eureka** 采用去中心化的 Peer to Peer 架构，每个节点都是对等的，不需要进行 Leader 选举。

### 总结

**Eureka** 是一个高可用、去中心化的服务注册与发现工具，它采用 AP 原则，通过牺牲一致性，来确保注册中心在网络故障或节点宕机时依然能够提供服务。其 **自我保护机制**、**自动切换** 和 **去中心化架构** 使得它非常适合在高可用性要求较高、跨多个机房的分布式系统中使用。



```
Eureka 的自我保护机制是一个关键的功能，它的设计目的是为了在微服务架构中增强服务注册中心的可用性和健壮性。这种机制特别适用于分布式环境中，这些环境可能会遇到不稳定的网络情况或者大量服务实例的同时失败。下面我们详细解释为什么 Eureka 会采用这样的设计：

### 1. 防止网络分区导致的服务下线

在微服务架构中，服务实例通常分布在多个网络区域。当服务注册中心（Eureka Server）由于网络问题暂时无法与一部分服务实例通信时（网络分区），它可能错误地认为这些无法通信的服务实例已宝际失效，导致它们被错误地从注册表中剔除。自我保护模式使得 Eureka 在检测到这种异常情况时，不会立即剔除这些服务实例，从而避免因暂时的网络问题而导致大规模服务下线，这对保持整个系统的稳定性至关重要。

### 2. 维护服务的高可用性

自我保护模式确保即使在网络不稳定或 Eureka Server 遭遇到异常高的失败检测时，客户端仍能从 Eureka 获取到注册的服务实例列表。这意味着，即使部分服务实例已实际失效，它们仍旧在注册表中可见，这允许客户端在这些实例恢复之前，有更多的时间去处理或迁移请求到其他健康实例，从而减少系统整体的不可用时间。

### 3. 保持注册表的完整性

通过自我保护机制，Eureka Server 在遇到大规模服务实例心跳失败的情况下，会尽量保持当前的服务注册表状态，避免因为心跳超时而清空服务列表。这种策略是基于一个假设，即“网络故障比服务实例同时大规模下线的可能性要高”，这通常是合理的，尤其是在大型分布式系统中。

### 4. 逐渐恢复正常状态

一旦网络问题解决，那些之前因网络分区或故障而未能维持心跳的服务实例会再次发送心跳到 Eureka Server。此时，Eureka Server 会更新这些服务实例的状态，并将新的或改变的信息同步到整个集群中。这种设计确保了服务注册信息能够在网络恢复后迅速更新，并反映最新的系统状态。

### 结论

通过这样的设计，Eureka 在遇到网络问题和服务故障时提供了更加鲁棒的服务发现机制。它优先保证整个系统的稳定性和服务的可用性，哪怕是以牺牲一部分的数据一致性为代价。这种权衡是微服务架构中常见的实践，尤其是在那些对服务可用性要求极高的场景中。
```



https://www.cnblogs.com/zzyang/p/17943039

动态配置服务：**Nacos提供了动态配置服务，支持配置的版本历史和回滚，以及灰度发布等 功能，这是Eureka、Zookeeper、Consul等缺乏的。**
支持DNS-based Service Discovery：Nacos提供了DNS-based Service Discovery功能，支持Kubernetes DNS、CoreDNS等，这是Eureka、Zookeeper、Consul等缺乏的。
数据持久化：**Nacos支持数据持久化，可以将服务注册信息和配置信息持久化道数据库中**，而Eureka默认不支持持久化。



临时实例和永久实例在Nacos中是一个**非常非常重要**的概念

之所以说它重要，主要是因为我在读源码的时候发现，临时实例和永久实例在底层的许多实现机制是完全不同的

**临时实例**

临时实例在注册到注册中心之后仅仅只保存在服务端内部一个缓存中，不会持久化到磁盘

这个服务端内部的缓存在注册中心届一般被称为**服务注册表**

当服务实例出现异常或者下线之后，就会把这个服务实例从服务注册表中剔除

**永久实例**

永久服务实例不仅仅会存在服务注册表中，同时也会被持久化到磁盘文件中

当服务实例出现异常或者下线，Nacos只会将服务实例的健康状态设置为不健康，并不会对将其从服务注册表中剔除

所以这个服务实例的信息你还是可以从注册中心看到，只不过处于不健康状态

这是就是两者最最最基本的区别

> 当然除了上述最基本的区别之外，两者还有很多其它的区别，接下来本文还会提到

这里你可能会有一个疑问

> 为什么Nacos要将服务实例分为临时实例和永久实例?

主要还是因为应用场景不同

**临时实例**就比较适合于业务服务，服务下线之后可以不需要在注册中心中查看到

**永久实例**就比较适合需要运维的服务，这种服务几乎是永久存在的，比如说MySQL、Redis等等

> MySQL、Redis等服务实例可以通过SDK手动注册

对于这些服务，我们需要一直看到服务实例的状态，即使出现异常，也需要能够查看时实的状态

> 所以从这可以看出Nacos跟你印象中的注册中心不太一样，他不仅仅可以注册平时业务中的实例，还可以注册像MySQL、Redis这个服务实例的信息到注册中心

在SpringCloud环境底下，一般其实都是业务服务，所以默认注册服务实例都是临时实例

这里还有一个小细节

在1.x版本中，一个服务中可以既有临时实例也有永久实例，服务实例是永久还是临时是由服务实例本身决定的

但是2.x版本中，一个服务中的所有实例要么都是临时的要么都是永久的，是由服务决定的，而不是具体的服务实例

所以在2.x可以说是**临时服务**和**永久服务**

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528837-905586867.png)

> 为什么2.x把临时还是永久的属性由实例本身决定改成了由服务决定?

其实很简单，你想想，假设对一个MySQL服务来说，它的每个服务实例肯定都是永久的，不会出现一些是永久的，一些是临时的情况吧

所以临时还是永久的属性由服务本身决定其实就更加合理了



### 2、CAP定理和BASE理论

谈到数据一致性问题，一定离不开两个著名分布式理论

- CAP定理
- BASE理论

CAP定理中，三个字母分别代表这些含义：

- C，Consistency单词的缩写，代表一致性，指分布式系统中各个节点的数据保持强一致，也就是每个时刻都必须一样，不一样整个系统就不能对外提供服务
- A，Availability单词的缩写，代表可用性，指整个分布式系统保持对外可用，即使从每个节点获取的数据可能都不一样，只要能获取到就行
- P，Partition tolerance单词的缩写，代表分区容错性。

所谓的CAP定理，就是指在一个分布式系统中，CAP这三个指标，最多同时只能满足其中的两个，不可能三个都同时满足

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528273-225636223.png)

为什么三者不能同时满足？

对于一个分布式系统，网络分区是一定需要满足的

而所谓分区指的是系统中的服务部署在不同的网络区域中

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528352-1526114972.png)

比如，同一套系统可能同时在北京和上海都有部署，那么他们就处于不同的网络分区，就可能出现无法互相访问的情况

当然，你也可以把所有的服务都放在一个网络分区，但是当网络出现故障时，整个系统都无法对外提供服务，那这还有什么意义呢？

所以分布式系统一定需要满足分区容错性，把系统部署在不同的区域网络中

此时只剩下了一致性和可用性，它们为什么不能同时满足？

其实答案很简单，就因为可能出现网络分区导致的通信失败。

比如说，现在出现了网络分区的问题，上图中的A网络区域和B网络区域无法相互访问

此时假设往上图中的A网络区域发送请求，将服务中的一个值 i 属性设置成 1

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528544-588182152.png)

**如果保证可用性**，此时由于A和B网络不通，此时只有A中的服务修改成功，B无法修改成功，此时数据AB区域数据就不一致性，也就没有保证数据一致性

**如果保证一致性**，此时由于A和B网络不通，所以此时A也不能修改成功，必须修改失败，否则就会导致AB数据不一致

虽然A没修改成功，保证了数据一致性，AB还是之前相同的数据，但是此时整个系统已经没有写可用性了，无法成功写数据了。

**所以从上面分析可以看出，在有分区容错性的前提下，可用性和一致性是无法同时保证的。**

虽然无法同时一致性和可用性，但是能不能换种思路来思考一下这个问题

首先我们可以先保证系统的可用性，也就是先让系统能够写数据，将A区域服务中的i修改成1

之后当AB区域之间网络恢复之后，将A区域的i值复制给B区域，这样就能够保证AB区域间的数据最终是一致的了

这不就皆大欢喜了么

这种思路其实就是BASE理论的核心要点，优先保证可用性，数据最终达成一致性。

BASE理论主要是包括以下三点：

- 基本可用（Basically Available）：系统出现故障还是能够对外提供服务，不至于直接无法用了
- 软状态（Soft State）：允许各个节点的数据不一致
- 最终一致性，（Eventually Consistent）：虽然允许各个节点的数据不一致，但是在一定时间之后，各个节点的数据最终需要一致的

BASE理论其实就是妥协之后的产物。

### 3、Nacos的AP和CP

Nacos其实目前是同时支持AP和CP的

具体使用AP还是CP得取决于Nacos内部的具体功能，并不是有的文章说的可以通过一个配置自由切换。

就以服务注册举例来说，**对于临时实例来说，Nacos会优先保证可用性，也就是AP**

对于**永久实例，Nacos会优先保证数据的一致性，也就是CP**

接下来我们就来讲一讲Nacos的CP和AP的实现原理

#### 3.1、Nacos的AP实现

对于AP来说，Nacos使用的是阿里自研的**Distro协议**

在这个协议中，**每个服务端节点是一个平等的状态，每个服务端节点正常情况下数据是一样的，每个服务端节点都可以接收来自客户端的读写请求**

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528584-2019455475.png)

当某个节点刚启动时，**他会向集群中的某个节点发送请求，拉取所有的服务实例数据到自己的服务注册表中**

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528600-2085582310.png)

这样其它客户端就可以从这个服务节点中获取到服务实例数据了

当某个服务端节点接收到注册**临时服务实例**的请求，不仅仅会将这个服务实例存到自身的服务注册表，同时也会向其它所有服务节点发送请求，将这个服务数据同步到其它所有节点

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528587-300147597.png)

所以此时从任意一个节点都是可以获取到所有的服务实例数据的。

即使数据同步的过程发生异常，服务实例也成功注册到一个Nacos服务中，对外部而言，整个Nacos集群是可用的，也就达到了AP的效果

同时为了满足BASE理论，Nacos也有下面两种机制保证最终节点间数据最终是一致的：

- 失败重试机制
- 定时对比机制

**失败重试机制**是指当数据同步【**给其它节点失败时，会每隔3s重试一次，直到成功**】

**定时对比机制**就是指，每个Nacos服务节点会定时向所有的其它服务节点发送一些认证的请求【收到旧的，将新的发送给该节点，收到新的就不用管】

这个请求会告诉每个服务节点**自己负责的服务实例**的对应的版本号，这个版本号随着服务实例的变动就会变动

如果其它服务节点的数据的版本号跟自己的对不上，那就说明其它服务节点的数据不是最新的

此时这个**Nacos服务节点就会将自己负责的服务实例数据发给不是最新数据的节点，这样就保证了每个节点的数据是一样的了**。

```
您提到的 **失败重试机制** 和 **定时对比机制** 是用于分布式系统中，保证多个服务节点之间的数据一致性和可靠性的策略。这些机制在分布式服务注册中心（如 Nacos）中尤为常见。让我详细解释这两种机制的原理和它们的作用：

### 1. **失败重试机制**

**定义**：  
失败重试机制指的是当某个服务节点在执行某项操作失败后，会进行一系列的自动重试，直到操作成功为止。

**场景**：
- 数据同步：在 Nacos 或类似的分布式服务注册中心中，服务节点之间的数据需要保持一致性。当一个节点更新数据时，需要将这些变更同步到其它节点。如果数据同步过程中出现网络波动或系统故障导致同步失败，就需要进行重试操作，确保数据最终能够成功同步。

**实现方式**：
- **定时重试**：在数据同步失败后，服务节点会启动定时任务，每隔3秒钟再重新尝试进行数据同步，直到成功为止。这种定时重试的方式，能够避免在短暂的网络故障下立即放弃同步操作，保证最终的数据一致性。
- **无损数据同步**：重试机制需要保证数据的完整性，每次重试时会重新检查要同步的数据是否发生了变化，确保不丢失重要的更新。

**优点**：
- 可靠性：通过不断重试，能够确保在网络故障、节点宕机等临时问题恢复后，最终能够成功将数据同步到目标节点。
- 容错性：允许系统在发生短暂故障时不立即放弃操作，而是通过多次重试最终完成任务。

### 2. **定时对比机制**

**定义**：  
定时对比机制指的是服务节点会定时向其它节点发送自身的状态和数据版本号，并与其它节点的数据进行对比。如果发现数据不一致，便会进行数据同步，确保所有节点的数据最终一致。

**场景**：
- 在一个分布式服务注册中心（如 Nacos）中，每个服务节点可能都拥有一部分服务实例的信息。这些信息会不断发生变化，例如当服务实例上线或下线时，其版本号也会随之改变。为了保证每个服务节点的数据都是最新的，系统需要定期检查其它节点的数据。

**实现方式**：
- **版本号比对**：每个 Nacos 服务节点会定时发送认证请求给其它节点，并附带自己所维护的服务实例的版本号。其它节点会收到这个请求并进行版本号对比。
  - 如果某个节点发现自己维护的版本号与发送请求的节点的版本号不一致，就意味着数据不一致。
- **数据同步**：一旦发现数据不一致，拥有最新版本数据的节点就会主动将自己的服务实例数据同步给那些数据落后的节点。这种方式通过主动同步的方式，保证每个节点最终拥有相同的最新数据。

**优点**：
- **数据一致性**：定时对比机制能够确保在多个节点上数据保持一致，不会因为某个节点的故障或网络问题导致部分节点的数据滞后。
- **低延迟同步**：通过定时比对机制，系统可以快速发现并修复数据不一致问题，不需要依赖手动操作。

### 两种机制的关系：
1. **失败重试机制** 确保当某个操作（如数据同步）失败时，系统可以自动进行多次重试，最终完成操作。它主要用于防止由于短期的网络故障、系统故障等导致的单次操作失败。
   
2. **定时对比机制** 则用于定期检查每个节点的数据状态，确保长期的一致性，即使没有主动的数据同步请求，它也会通过对比版本号来发现并修复数据不一致的情况。

### 例子：
- 假设有三个 Nacos 节点 A、B 和 C。节点 A 更新了服务实例数据，并尝试同步到节点 B 和 C。
  - **失败重试机制**：如果节点 A 在同步数据给 B 时失败，A 会每隔 3 秒重试，直到同步成功。
  - **定时对比机制**：假设由于网络问题，A 无法同步到 C。此时，定时对比机制启动，C 会定期向 A 和 B 发送版本号认证请求。一旦 C 发现它的数据版本号与 A 不一致，A 会将最新的数据同步给 C，确保数据一致性。

### 总结：
- **失败重试机制** 提供了短期的容错能力，确保在失败情况下通过多次重试完成操作。
- **定时对比机制** 则提供了长期的数据一致性保障，通过版本号对比及时发现数据不一致，并进行数据同步。

这两种机制相互配合，能够保证 Nacos 服务节点之间的数据一致性和系统的高可用性。
```



#### 3.2、Nacos的CP实现

Nacos的CP实现是基于Raft算法来实现的

在1.x版本早期，Nacos是自己手动实现Raft算法

在2.x版本，Nacos移除了手动实现Raft算法，转而拥抱基于蚂蚁开源的JRaft框架

在Raft算法，每个节点主要有三个状态

- Leader，负责所有的读写请求，一个集群只有一个
- Follower，从节点，主要是负责复制Leader的数据，保证数据的一致性
- Candidate，候选节点，最终会变成Leader或者Follower

集群启动时都是节点Follower，经过一段时间会转换成Candidate状态，再经过一系列复杂的选择算法，选出一个Leader

![img](https://img2024.cnblogs.com/blog/2880613/202403/2880613-20240312164528632-1668395587.png)

> 这个选举算法比较复杂，完全值得另写一篇文章，这里就不细说了。不过立个flag，如果本篇文章点赞量超过28个，我连夜爆肝，再来一篇。

当有写请求时，如果请求的节点不是Leader节点时，会将请求转给Leader节点，由Leader节点处理写请求

比如，有个客户端连到的上图中的`Nacos服务2`节点，之后向`Nacos服务2`注册服务

`Nacos服务2`接收到请求之后，会判断自己是不是Leader节点，发现自己不是

此时`Nacos服务2`就会向Leader节点发送请求，Leader节点接收到请求之后，会处理服务注册的过程

为什么说Raft是保证CP的呢？

主要是因为Raft在处理写的时候有一个判断过程

- 首先，Leader在处理写请求时，不会直接数据应用到自己的系统，而是先向所有的Follower发送请求，让他们先处理这个请求
- 当超过半数的Follower成功处理了这个写请求之后，Leader才会写数据，并返回给客户端请求处理成功
- 如果超过一定时间未收到超过半数处理成功Follower的信号，此时Leader认为这次写数据是失败的，就不会处理写请求，直接返回给客户端请求失败

所以，一旦发生故障，导致接收不到半数的Follower写成功的响应，整个集群就直接写失败，这就很符合CP的概念了。

不过这里还有一个小细节需要注意

Nacos在处理查询服务实例的请求直接时，并不会将请求转发给Leader节点处理，而是直接查当前Nacos服务实例的注册表

这其实就会引发一个问题

如果客户端查询的**Follower节点没有及时处理Leader同步过来的写请求（过半响应的节点中不包括这个节点），此时在这个Follower其实是查不到最新的数据的，这就会导致数据的不一致**

所以说，虽然Raft协议规定要求从Leader节点查最新的数据，但是Nacos至少在读服务实例数据时并没有遵守这个协议

当然对于其它的一些数据的读写请求有的还是遵守了这个协议。

> JRaft对于读请求其实是做了很多优化的，其实从Follower节点通过一定的机制也是能够保证读到最新的数据
