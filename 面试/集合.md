## hashmap

```
get，hash算法+euqals
put，hash算法+更新或者创建
扩容，如果超过阈值：原容量*0.75，创建原来2倍的数组，然后将元素进行迁移，index&旧容量 == 0则放入新的hash表的index位置，不为0则放入新的hash表的index+旧容量位置，通过位运算避免重新计算哈希值，扩容后元素会被均匀分布到新数组的前后两部分。
```

hashMap的寻址算法

1.hashcode()生成32位的值

2.hash()进行二次哈希，(hash >> 16) ^ hash让高位参与运算

3.hash & （n-1）

如果仅使用原始哈希值的低位来计算数组索引，那么即使 `hashCode()` 方法返回的高位随机性很好，但低位没有足够的混合，也可能导致较多的哈希冲突。例如，当数组大小为 16 时，只有哈希值的低 4 位起作用，高位的变化根本不会影响最终的数组索引。

**操作**：将高位信息与低位混合 `(hash >> 16) ^ hash`，从而增强哈希值的随机性和均匀性，确保最终计算出的哈希桶索引更加分散，减少冲突。

```
例子
假设有一个简单的哈希值 hash = 0b10010010010010010010010010010010（二进制表示）。我们可以看到它的低 16 位和高 16 位之间的模式可能有很大差异。

右移 16 位得到高 16 位：0b1001001001001001。
原始哈希值 hash 与高位进行异或：
bash
复制代码
(hash >> 16) ^ hash = 0b1001001001001001 ^ 0b10010010010010010010010010010010
通过异或混合高位和低位，就可以得到一个比原始哈希值更具均匀性的结果。混合后的哈希值不仅依赖于低位，也包含了高位信息，从而提高了散列分布的均匀性。
```



### (n - 1) & hash

使用与操作可以直接取出哈希值的低几位，而这正是与对 `n` 取模效果相同的结果

```
为什么只对 2 的幂有效？
只有当 n 是 2 的幂时，n - 1 才会是形如全 1 的二进制数。
定位元素时，对于非 2 的幂，(n - 1) & hash 并不能保证等价于 hash % n 的效果，因为此时位与运算无法正确处理余数。
扩容时，index&旧容量 == 0，原索引的高位为 0 的元素保留在原位置。所有元素都会重新分布到新数组的前半部分（index）或后半部分（index + oldCapacity）。
```





### 并发死链

1.a->b,线程1来了挂起（对线程1来说e指向a，next指向b），线程2来了变为b->a,线程1继续执行把a插入表头，再将b插入表头，此时e指向b的next即a，再把a插入表头，b.next = a, 但刚才b.next = a，出现环，并发死链





#### copyOnWrite

```
这段代码和解释描述的是如何在无锁情况下实现读写操作的一致性，这种方式类似于某些实现中的“读写分离”或“乐观更新”机制，确保读操作一直是安全的。下面详细解释为什么更新操作不会有并发问题，以及在读取操作时可能会得到旧值还是新值。

### 核心思路
代码使用了一种通过复制数组、并更改引用来实现无锁并发读写的方式。这种设计的主要目的是确保读操作不需要锁，同时写操作可以通过更换整个数组来保证一致性。下面具体解释每一个操作：

1. **写操作（插入新元素）**：
   - 当有一个新元素需要插入时，首先创建一个新的数组，它的长度是原数组的长度 + 1。
   - 然后把原数组中的元素全部复制到新数组，并在新数组的最后一位插入新的元素。
   - 最后，将新的数组地址替换掉原来的数组地址（相当于一个引用指向的改变）。

2. **读操作**：
   - 读操作通过 `getArray()` 获取当前数组引用并读取目标下标的值。
   - 因为对数组的引用替换是**原子操作**（参考 Java 中引用变量的赋值是原子的），所以读操作要么读取到旧数组，要么读取到新数组，这样的设计避免了数据不一致的风险。

### 为什么更新操作不会有并发问题？
1. **原子性引用切换**：
   - 写操作并不是直接在原数组上进行修改，而是通过创建一个新的数组，然后通过引用替换的方式进行更新。
   - Java 中的引用赋值操作是原子的，这意味着当执行 `arrayReference = newArray` 时，读操作要么看到原来的数组，要么看到新的数组，不会处于一种中间状态。

2. **读操作的一致性**：
   - 当一个线程在读操作时，如果数组引用还没有被更新，它就读取原数组的值。
   - 如果在读操作过程中，写线程已经把数组替换为新数组，读操作就会直接读取新数组的值。
   - 由于整个替换过程是原子性操作，所以不会出现部分更新或数据不一致的情况。

3. **读写之间的隔离**：
   - 读操作从逻辑上是基于快照的，因为读线程要么看到旧数组，要么看到新数组。每次写操作都是在一个新的数组上完成，最后通过更换引用完成数据的“切换”。
   - 这样，读线程不会看到写线程正在修改数组的中间状态，因此实现了读写之间的隔离。

### 如果一个线程读取下标 `x`，另一个线程对下标进行更新，会发生什么？
- **读取时得到旧值还是新值**：
  - 如果一个线程在执行读取下标 `x` 的时候，另外一个线程正在执行更新操作，那么读线程可能会读取到旧数组中的值，也可能读取到新数组中的值，这取决于更新操作是否已经完成引用切换。
  - 如果写操作已经完成了引用切换，读线程会读取到**新数组中的值**。
  - 如果写操作还未完成引用切换，读线程会读取到**旧数组中的值**。
  
- **不会读取到不一致的状态**：
  - 由于写操作是在新数组上完成的，并且整个引用替换是原子操作，所以读线程要么读取到更新前的数据，要么读取到更新后的数据，不会读取到一个“部分更新”的状态。

### 结论
- **一致性**：由于读操作只是在数组的一个快照上进行，不论这个数组是旧的还是新的，都可以确保读取到一致的数据。
- **无锁读**：读操作不需要加锁，因为读取数组引用本身是安全的。读操作的效率非常高，无需等待写操作完成。
- **最终一致性**：写操作在数组引用切换后，所有后续的读操作都将读取到更新后的新值。因此，对于任何更新，最终所有的读取都会是最新的数据。

这种方式非常适合**读多写少**的场景，因为它最大化了读操作的并发性，降低了锁的开销。典型的应用场景包括一些缓存实现、系统配置快照、状态快照等。
```



# ConcurrentHashMap

https://mp.weixin.qq.com/s?__biz=MzA5MzI3NjE2MA%3D%3D&chksm=886343d8bf14cacec26559e76ee963320e3656f13ae161f950185d728c8d529a540204badc1f&idx=1&mid=2650256055&scene=27&sn=ede9090cf1bc9b224644de48a439fbd8&utm_campaign=geek_search&utm_content=geek_search&utm_medium=geek_search&utm_source=geek_search&utm_term=geek_search#wechat_redirect

https://mp.weixin.qq.com/s?__biz=MzA5MzI3NjE2MA%3D%3D&chksm=88635dccbf14d4da6a5e53d13ef063a87842d38963a7c047e2ceb7c5ccb5d5ea01ec3cc1c3ab&idx=1&mid=2650254499&scene=27&sn=5b5120f89127196d4cfa753329d58407&utm_campaign=geek_search&utm_content=geek_search&utm_medium=geek_search&utm_source=geek_search&utm_term=geek_search#wechat_redirect

```
1.private transient volatile int sizeCtl;
// 4种状态：0尚未初始化，-1正在初始化, -（1+n）正在扩容：n是扩容线程数, 大于0是容量
2.basecount,countCell[]，首先尝试修改basecount，如果遇到竞争，则创建countcell数组，cas修改数组元素的值，如果还遇到竞争，则hash以后再修改
3.forwardingnode，将扩容操作平均到插入操作中，每次插入有六分之一的被迁移
4.get时遇到forwardingnode会去新数组中查找
5.put时首先看hashmap是否被创建，懒加载cas创建hashmap，再看该节点是否被创建cas创建，然后syn对表头加锁进行插入，如果在扩容期间put则会帮忙扩容
```

<img src="/Users/haozhipeng/Library/Application Support/typora-user-images/image-20241102155647417.png" alt="image-20241102155647417" style="zoom: 33%;" />



<img src="/Users/haozhipeng/Library/Application Support/typora-user-images/image-20241102160036885.png" alt="image-20241102160036885" style="zoom:33%;" />



为了确保数据访问的正确性，Java 8 引入了 `ForwardingNode` 节点。当某个桶已经迁移完毕时，`HashMap` 会在旧数组的对应位置放置一个 【`ForwardingNode`，这个节点指向新数组 `newTable`。】

当 `get` 操作遇到 `ForwardingNode`，它会自动跳转到新数组中继续查找。这就确保了即使在扩容过程中，`get` 也能够找到数据。

1. - 平均来说，每次插入操作或者有线程参与迁移时，**只有 1/6 的节点会被立即迁移**。
   - 这样可以避免大量节点的集中迁移导致系统卡顿，扩容的压力被分散到多次操作中，从而减小系统的瞬时负载，保证扩容过程对系统性能的影响最小。

```
扩容过程中读写操作的处理
put 操作：
如果有新线程在扩容期间进行 put 操作，首先会检查当前桶是否已经被迁移。【如果尚未迁移，它可以帮助迁移该桶，然后继续执行插入操作；】如果已经迁移到 newTable，它会直接在 newTable 上执行插入。
get 操作：
在 get 操作期间，可能会遇到 ForwardingNode，表示该桶已经迁移到了 newTable。此时，get 操作会直接转向 newTable 继续查找，这样可以确保扩容期间的读取操作不被阻塞。
```

sizeCtl默认为0，在正常情况下，他表示ConcurrentHashMap的阈值，是一个正数。当数组正在扩容时，他的值为-1，表示当前正在初始化，其他线程只需要判断sizeCtl==-1 ，就知道当前数组正在初始化。但当ConcurrentHashMap正在扩容时，sizeCtl是一个表示当前有多少个线程正在协助扩容的负数

那么每个线程如何分配到对应的自己的CounterCell呢？ConcurrentHashMap中采用了类似HashMap的思路，获取线程随机数，再对这个随机数进行取模得到对应的CounterCell。【获取到对应的CounterCell之后，当前线程会尝试使用CAS进行修改，如果修改失败，则重新获取线程随机数，换一个CounterCell再来一次，直到修改成功。】



### 扩容流程

那么， 在①处：意味着当前线程还没处理完此区域的扩容任务，因为还未超过边界bound；在②处：意味着已经没有区域要分配了，要不就是都处理完了，要不就是所有区域都有其他线程在处理了，不再需要当前线程的参与了；在③处：是否还记得stride？代表每个区域的长度。所有进入的线程，通过CAS拿到自己负责的区域，并更新transferIndex，记住边界bound，以及当前处理的索引位置；过程如图：

<img src="https://mmbiz.qpic.cn/mmbiz_png/v1LbPPWiaSt4N72WmYXdcsnLf4ZKR96G4ialZ1rztjdBaE0GEBdhic0BpkicwVtNbatc5qo5ics53dSia46GmgoU1bibQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"  />

可以简单说明的是，TRANSFERINDEX 为 transferIndex的内存地址，因对transferIndex的更新有竞争条件，，通过CAS操作就可以保证对transferIndex操作的原子性。CAS操作可以简单理解为由底层保证的单一变量的原子操作，接受对象地址，预期值，要更新的值为参数，当预期值符合，并成功把值设置为要更新的值时，返回true。

因此，通过竞争更新transferIndex的值，线程就获得了table上某段区域的扩容任务，nextIndex(预期值，要知道transferIndex可能在调用CAS前改变了)辅助了参与CAS竞争。









### LinkedHashMap

![image-20240910110301398](/Users/haozhipeng/Library/Application Support/typora-user-images/image-20240910110301398.png)

```java
class LRUCache {
    private int capacity;
    private LinkedHashMap<Integer, Integer> cache;
    public LRUCache(int capacity) {
        this.capacity = capacity;
        cache = new LinkedHashMap<Integer, Integer>(capacity,0.75F,true){
            @Override
            protected boolean removeEldestEntry(Map.Entry<Integer,Integer> entry){
                return size() > LRUCache.this.capacity;
            }
        };
    }
    
    public int get(int key) {
        return cache.getOrDefault(key,-1);
    }
    
    public void put(int key, int value) {
        cache.put(key,value);
    }
}
```



### linkedlist和arraylist储存相同元素，后者消耗更多

```
在比较 `LinkedList` 和 `ArrayList` 存储相同的元素时，它们的内存消耗不同，主要原因在于它们的内部结构以及如何管理元素。让我们详细讨论这两种数据结构的内存消耗。

### 1. **ArrayList 内存消耗**
`ArrayList` 是基于动态数组实现的，它在内部使用一个连续的数组来存储元素。`ArrayList` 的内存消耗主要由以下几个方面构成：

- **对象本身的开销**：`ArrayList` 对象有一些固定的开销，比如用于存储元素数量、数组的容量等信息的字段。
  
- **内部数组**：`ArrayList` 使用一个数组来存储元素。初始容量（默认为 10）通常比实际元素数量稍大，以避免频繁扩容。在存储时，`ArrayList` 会分配一块连续的内存来存放数组中的元素。每个元素在数组中占用一个引用（即一个指向实际对象的指针），并且数组本身占用一块内存。

- **扩容机制**：当 `ArrayList` 的容量不足时，它会重新分配一个更大的数组（通常扩容为当前容量的 1.5 倍或 2 倍），并将旧数组中的元素复制到新数组中。扩容期间会有暂时的内存浪费，因为旧数组依然占用内存，直到复制操作完成。

因此，`ArrayList` 在内存消耗上有一定的浪费，特别是当数组容量超过实际存储的元素数量时。

### 2. **LinkedList 内存消耗**
`LinkedList` 是基于双向链表实现的。链表中的每个节点包含三个主要部分：元素值、指向下一个节点的指针和指向前一个节点的指针。`LinkedList` 的内存消耗包括以下几个方面：

- **对象本身的开销**：类似 `ArrayList`，`LinkedList` 对象也有一些固定的开销，比如头节点、尾节点以及存储大小等信息的字段。

- **节点的开销**：`LinkedList` 中的每个元素都是一个节点，每个节点都有三个部分：
  - **元素值**：存储实际的数据元素（引用）。
  - **前驱指针**：指向前一个节点。
  - **后继指针**：指向下一个节点。

  因此，每个节点需要额外的指针（两个指针，前一个和后一个），这比 `ArrayList` 的单个引用多出了一些内存开销。

- **非连续内存分配**：`LinkedList` 中的节点不需要连续存储，系统会为每个节点动态分配内存。虽然这避免了像 `ArrayList` 扩容时的内存复制，但由于节点之间的跳转需要额外的指针，并且每个节点占用的空间更多，因此其整体内存使用效率比 `ArrayList` 低。

### 3. **内存消耗对比**

- **ArrayList 的内存效率**：
  - `ArrayList` 只需要为每个元素存储一个引用（指向对象的指针）。
  - 因为其底层是数组，数据是连续存储的，内存局部性好（有利于缓存命中率），且每个元素除了它的引用外没有额外的内存开销（除了可能的扩容带来的少量浪费）。
  
- **LinkedList 的内存效率**：
  - `LinkedList` 每个节点除了存储数据，还需要额外存储两个指针（前驱和后继），因此它每个元素的内存开销比 `ArrayList` 大。
  - 由于每个节点是分散存储的，内存分配并不连续，这可能会降低缓存效率，导致更多的内存占用和访问开销。

### 4. **总结**

- **ArrayList 内存消耗较少**：对于存储大量相同的元素，`ArrayList` 通常比 `LinkedList` 消耗更少的内存。因为 `ArrayList` 的内存开销仅包括数据存储和数组扩容时的多余容量，而 `LinkedList` 由于每个节点需要额外的两个指针，导致每个元素的内存开销更大。

- **LinkedList 内存消耗较多**：`LinkedList` 在每个元素上都增加了指针的开销，并且由于非连续内存存储，可能会导致更多的内存碎片化和低效的缓存命中。

因此，在存储大量相同的元素时，`ArrayList` 通常更节省内存。`LinkedList` 的额外指针和节点管理会导致其内存使用明显高于 `ArrayList`。
```

