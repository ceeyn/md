id映射

​	冷启动

​	订阅id变更的流水

生成、同步bitmap

​	上游生成

​	同步（交互、查bitmap数据、反序列化、分段、存bitmap（元数据、分段数据））

下游使用：

​	bid判存

​	bitmap 分页拉取



冷启动时：

全量业务id 转换成 正向映射【uid-》bit】 反向映射【bit -》uid_corpId】，同时写到下游的kafka【目的：写正向映射，提供给生成bitmap】

有新注册的业务id：

我们消费【新注册上报】流水，生成正向和反向映射，同时写到下游的kafka

```
// UserGroupBmp 人群包数据
type UserGroupBmp struct {
	// UserGroupID 用户群id
	UserGroupID int64 `db:"user_group_id"`
	// ImpDate 日期分区
	ImpDate int64 `db:"imp_date"`
	// HashPart hash分段
	HashPart int64 `db:"hash_part"`
	// BmpCount 人群bitmap总数
	BmpCount int64 `db:"bmp_count"`
}

```

查starrocks

```
userGroupID = BitmapID
GetUserGroupBmps 根据userGroupID查询user_group_bmp表数据
GetBitmapSyncData调用GetUserGroupBmps返回userGroupBmps，然后分10000段，：select user_group_id, imp_date, bitmap_count(bmp) as bmp_count from user_group_bmp where user_group_id=%v", userGroupID 查出来rows，返回

// 反序列化db bitmap数据
bitmap, err := GetBitmap(ctx, bitmapData)
// bitmap分段
cardinality, length, step, segmentIndex, segmentBitmaps, err := Segment(ctx, bitmap)
bitmapSegmentSave 分段bitmap存redis 
key := fmt.Sprintf("%s_%v_%v", BitmapSegmentDataKey, info.BitmapID, k)
// bitmap 元数据信息使用hash存储 key BitmapID val hash
err := dao.SetBitmapSegmentInfo(ctx, info, expireTime)
// bitmap 分段数据序列化后使用kv存储 key id+段号（0-100）val 相应段转为base64
err = dao.SetBitmapSegmentData(ctx, info, expireTime)
```

上游生成一些人群包的bitmap（例如：最近三天参会的人）存入startRocks，我们使用SyncBitmapData方法【BidType，BitmapID】从startRocks查出来同步bitmap数据，分段后存入redis，本地缓存分段信息和分段数据，

当需要判存时，根据bitmapId获取本地缓存BitmapSegmentInfo，获取业务id对应bit位，计算业务id所属分段bitmap，从 BitmapSegmentInfo获取bitmap分段对应索引为0，说明该分段bitmap为空，bitmap分段对应索引不为，说明该分段bitmap有值，需要查询该分段bitmap，从BitmapSegmentDataCache中获取分段

需要分页拉取时，根据bitmapId获取本地缓存BitmapSegmentInfo，计算请求中的offset所属分段bitmap，获取分段bitmap

```
GetBitmapDataByPage 从数据库中分页获取 bitmap 数据，并将其解析为 int64 切片。
sql := fmt.Sprintf("select bitmap_to_string(sub_bitmap(bmp, %v, %v)) as bitmap_str from user_group_bmp "+
		"where user_group_id=%v AND imp_date=%v limit 1", offset, len, userGroupID, impDate)
```



在压测（性能测试）中，制定策略并进行实际测试时，需要考虑多个因素来确保系统在高负载下的表现符合预期。下面详细介绍压测策略及如何评估性能：





```
面试官可能会针对以下几个方面提出问题：

应用场景：

这个位图同步系统主要应用于哪些业务场景？
为什么选择使用位图来管理用户群数据，有什么优势？
系统设计与实现细节：

如何设计正向和反向映射？为什么需要这两种映射？
位图同步到Redis的分段策略是怎样的？为什么要进行分段？
为什么使用StarRocks存储位图，而不是其他数据库？
如何保证数据同步的一致性？
性能与优化：

如何确保位图数据的高效查询？
在系统的性能优化上采取了哪些措施？
位图的分段存储对性能提升有什么作用？
数据一致性与可靠性：

如果同步过程中出现故障，如何处理数据不一致的问题？
新注册的业务ID如何确保实时更新并与下游保持一致？
技术选型：

为什么选择Kafka来实现数据传输？
在Redis中存储分段数据时，为什么使用哈希和键值对的方式？
挑战与学习：

在实现这个系统时遇到了哪些技术挑战？你是如何解决的？
你从这个项目中学到了哪些关键技能？
```



```
情境（Situation）：
在实习期间，公司需要构建一个高效的数据管理系统，用于管理和分析大规模用户群体数据，以支持精准营销和用户行为分析。系统需要处理冷启动场景中的全量业务ID映射、新业务ID注册同步，以及大规模人群位图的分段存储和高效查询，确保数据的一致性和实时性。

任务（Task）：
我负责设计和维护一个ID映射和位图同步系统，解决以下几个关键问题：

实现冷启动时全量业务ID的正向和反向映射生成。

处理新注册业务ID的实时同步。

实现位图的高效同步、分段存储，并确保下游服务的数据检索效率。

行动（Action）：

冷启动与ID映射生成：
在冷启动阶段，我负责将所有业务ID转换为正向和反向映射。具体来说，正向映射将业务ID转换为位(bit)，反向映射则将位转换回业务ID和公司ID对。这些映射通过Kafka流式传输到下游系统，从而实现位图的高效生成，这是管理大规模用户群信息的关键过程。

新业务ID注册：
对于新注册的业务，我实现了消费注册事件并更新正向和反向映射的机制。这还包括将更新后的映射推送到Kafka，以确保下游系统与最新数据保持同步。

位图同步与存储：
上游系统生成了基于人群的位图，例如最近三天参与活动的用户群，并将其存储在StarRocks中。我使用一个名为SyncBitmapData的方法，从StarRocks中获取这些位图，将其分段后保存到Redis中，以便进行高效查询。我们维护了分段元数据和位图数据的本地缓存，这显著提高了系统在存储和检索方面的性能。

使用场景 - 存在性检查与分页检索：
为了确定某个业务ID是否存在，我使用本地缓存BitmapSegmentInfo定位相应的位段，并评估该位图段是否为空。如果段内有数据，则从BitmapSegmentDataCache中检索该位图以确认存在性。此外，对于分页检索，我使用本地缓存来识别请求中偏移量对应的正确位图段，并获取所需的位图数据，从而确保高效的数据访问。

结果（Result）：
通过以上工作的实施，我成功构建了一个高效的ID映射和位图同步系统。该系统实现了：

数据同步效率的显著提升：通过Kafka和Redis组合使用，确保了数据的实时同步和一致性。

查询性能的优化：通过位图的分段存储和本地缓存，大幅减少了查询时间，系统能够快速响应用户群体的查询请求。

支持业务需求：系统支持公司精准营销和用户行为分析需求，确保能够高效管理和分析大规模用户群体数据。

这段经历让我深入理解了如何设计可扩展的系统，涉及上下游服务之间的实时同步，高效处理大规模用户群数据，以及优化位图分段以实现快速检索。
```



### 实时性

```
从你提供的描述来看，涉及到一个**bitmap**的生成、同步和使用的流程，尤其是在处理用户群体包（UserGroupBmp）的过程中。整个流程中的实时性分析可以从不同的环节来讨论，具体来看：

### 1. **上游生成 bitmap 实时性**

上游生成 bitmap 的过程主要依赖于业务逻辑（例如：最近三天参会的人），这通常不是一个实时需求场景。因为这类用户群包生成的过程可能涉及数据聚合和批处理，所以一般是按**定时任务**或**定期触发**。在这种情况下，实时性通常不会是最高优先级。

- **瓶颈**：如果上游生成 bitmap 涉及大量的数据处理和复杂的查询，可能会导致延迟。这一部分的实时性可能是中等的，依赖于任务的调度频率。
- **提升建议**：可以通过分布式计算、预聚合等技术手段加快 bitmap 的生成，减少延迟。

### 2. **数据同步到下游的实时性**

通过 `SyncBitmapData` 方法，从 StarRocks 查询 bitmap 数据，并将其分段存储到 Redis 以及本地缓存。这个过程对实时性有较高要求，因为下游的系统可能需要依赖这些数据进行进一步的操作，例如判定某个业务 ID 是否在某个群体中。

- **优势**：使用 Redis 和本地缓存存储分段后的 bitmap 数据，缓存访问速度很快，能够提高查询的实时性。这意味着在数据同步完成后，系统的判存与查询操作具有很高的实时性。
  
- **潜在延迟**：数据同步的实时性主要取决于从 StarRocks 查询数据、进行分段、序列化以及写入 Redis 的速度。这些操作可能会产生一定的延迟，尤其是当 bitmap 数据量较大时，分段和序列化可能会成为瓶颈。
  
- **提升建议**：可以通过**异步同步**的方式，避免数据同步阻塞下游的使用。还可以利用**并行查询和分段处理**来加速 bitmap 数据的同步，缩短分段和序列化的时间。

### 3. **本地缓存和 Redis 的使用**

一旦 bitmap 数据被分段并存储到 Redis 或本地缓存中，判存和分页拉取的实时性非常高。Redis 的访问速度通常是毫秒级的，而本地缓存的读取速度更快，几乎可以做到**实时响应**。

- **实时性高**：基于 Redis 和本地缓存的实现可以极大提升系统的响应速度，特别是用于判存和分页拉取时。只要 bitmap 数据已经同步完成，判存和分页拉取的实时性几乎不会有任何延迟。
  
- **潜在问题**：如果 bitmap 数据尚未同步完成，或者 Redis 或本地缓存数据不一致，可能会导致查询失败或结果不准确。因此，数据同步时的延迟会直接影响到下游判存的实时性。

### 4. **新注册业务 ID 的处理实时性**

对于新注册的业务 ID，你提到系统会通过消费上报的流水，生成正向和反向映射，并将其写入下游的 Kafka。这一环节的实时性主要取决于消息队列和消费的处理速度。

- **消息处理延迟**：如果 Kafka 消息消费速率较慢，或者系统中存在大量待处理的注册 ID，可能会产生延迟。
  
- **实时性分析**：总体来说，通过 Kafka 处理的新注册 ID 流水一般会有较高的实时性，通常在秒级甚至毫秒级完成映射与同步。因此，这一部分的实时性通常较高。

### 5. **分页拉取的实时性**

分页拉取 bitmap 数据的操作依赖于存储在本地缓存或 Redis 中的分段数据。如果数据已经预先分段存储到 Redis 或本地缓存中，那么分页拉取的实时性会非常高。

- **高实时性**：分页拉取的实时性依赖于 Redis 的读取速度，通常情况下能在毫秒级响应。如果数据是从缓存中直接获取，性能会更好，延迟几乎可以忽略。
  
- **潜在延迟**：如果分页拉取的数据还未同步到 Redis 或本地缓存中，系统需要从数据库查询，并执行反序列化操作，这时会引入一定的延迟。

### 总结：实时性分析

1. **上游 bitmap 生成**：实时性较低，通常是定时任务或批处理，存在延迟。
2. **数据同步**：同步到 Redis 和缓存的过程可能会有延迟，但如果优化得当，通常可以控制在秒级别。
3. **本地缓存与 Redis 查询**：查询速度非常快，具有较高的实时性。
4. **Kafka 消费新注册业务 ID**：实时性通常较高，处理速度依赖于消息队列的消费速率。
5. **分页拉取**：如果数据已分段存储在 Redis 中，实时性很高，通常毫秒级响应；如果需要从数据库查询，会有一些延迟。

总体来说，系统在**bitmap 数据已经同步完成**的情况下，**判存和分页拉取**的实时性可以做到非常高，通常在毫秒级。然而，数据同步和新注册 ID 处理的延迟会对整体实时性有一定的影响。
```









### 压测策略概述

1. **确定性能目标**：明确性能指标，如响应时间（p99），每秒请求数（QPS），和成功率（错误率）。

2. **设计测试用例**：根据系统的特点设计不同的测试用例，包括正常负载和压力负载测试。

3. **选择合适的工具**：常用的压测工具有 Apache JMeter、Gatling、Locust 等，选择合适的工具来模拟负载。

4. **配置测试环境**：确保测试环境尽可能接近生产环境，以获得真实的测试结果。

5. **执行压测**：根据策略逐步增加负载，记录响应时间、QPS、成功率等指标。

6. **分析结果**：根据测试结果分析系统的性能瓶颈，调整系统配置或优化代码，进行再次测试。

### 压测策略实例

#### 场景 1：p99 响应时间在 200ms 以内，成功率在 99.99% 的情况下，最大 QPS

**目标**：
- 响应时间 p99 ≤ 200ms
- 成功率 ≥ 99.99%

**步骤**：
1. **设置负载**：从较低的 QPS 开始测试，逐步增加负载，直到达到系统的性能极限。

2. **监控指标**：
   - 响应时间的 p99（即99%的请求的响应时间在200ms以内）。
   - 成功率（请求成功的比例）。
   - 系统资源使用情况（CPU、内存、网络等）。

3. **分析**：
   - 当 p99 响应时间仍然在 200ms 以内且成功率满足 99.99% 时，记录当前的 QPS 值。
   - 继续增加负载，直到 p99 响应时间超出 200ms 或成功率低于 99.99% 为止。

**例子**：
假设在测试中，当 QPS 为 30,000 时，p99 响应时间仍然在 200ms 以内，成功率为 99.99%。此时最大 QPS 为 30,000。

#### 场景 2：p99 响应时间在 200ms 以内，QPS 为 30,000 时，查看成功率

**目标**：
- 响应时间 p99 ≤ 200ms
- QPS = 30,000

**步骤**：
1. **设置负载**：配置压测工具以模拟 30,000 QPS。

2. **监控指标**：
   - 响应时间的 p99（应确保 ≤ 200ms）。
   - 成功率（计算在这种负载下的实际成功率）。

3. **分析**：
   - 在 QPS 为 30,000 的情况下，记录系统的实际成功率。
   - 如果成功率低于预期，可能需要优化系统性能或调整配置。

**例子**：
假设在 QPS 为 30,000 时，p99 响应时间确实在 200ms 以内，但成功率为 99.5%。这表明系统可能在高负载下出现了一些问题，需要进一步优化。

### 总结

1. **在压力测试中**：
   - 逐步增加负载，监控性能指标。
   - 找到系统在给定性能目标下的最大承载能力。

2. **评估和优化**：
   - 根据测试结果评估系统性能。
   - 优化代码、调整配置，以提高系统性能并满足性能目标。

通过这些策略和步骤，你可以有效地进行压测，确保系统在实际生产环境中能够稳定地满足性能要求。





