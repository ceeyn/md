

，[预训练-微调](https://zhida.zhihu.com/search?content_id=254177277&content_type=Article&match_order=1&q=预训练-微调&zhida_source=entity)（pre-training fine-tuning）是主流的微调方法。这种方法通常分为两个阶段：首先，模型在大规模通用数据（如互联网文本）上进行预训练，学习通用的语言表示；然后，针对特定任务（如文本分类、机器翻译等），在较小的任务专用数据集上进行微调。虽然这种方法在许多任务上表现优异，但它存在明显的局限性。

首先，每个任务都需要单独的微调过程，这意味着每次面对新任务时，都需要重新训练模型，导致计算资源消耗大、成本高。对于企业或研究机构来说，这种高成本的方式显然不够高效。其次，微调过程需要大量的任务专用数据，这在数据稀缺的领域（如医疗、法律等）尤为困难。例如，在医疗领域，获取高质量的标注数据不仅成本高昂，还涉及隐私和伦理问题。此外，模型在微调后往往对预训练阶段学到的通用知识产生“灾难性遗忘”，即模型在适应新任务时，可能会丢失之前在预训练阶段学到的通用语言理解能力，从而限制了其在新任务上的泛化能力。

作者：Deep Man
链接：https://zhuanlan.zhihu.com/p/25775384311
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



随着研究的深入，提示词微调（prompt fine-tuning）逐渐成为了一种更高效的替代方案，解决了传统预训练-微调方法中的诸多局限性。这种方法的核心思想是通过设计提示词（prompt）来引导模型生成所需的输出，而不是对模型进行全面微调。例如，在文本分类任务中，可以通过设计如“这篇文章的主题是__”这样的提示词，让模型直接生成类别标签，而不需要对整个模型进行重新训练。这种方式不仅简化了任务处理的流程，还显著降低了技术使用的门槛。

提示词微调的优势在于其灵活性和高效性。首先，它减少了对任务专用数据的依赖，特别适合少样本甚至零样本学习的场景。在许多实际应用中，获取大量标注数据既昂贵又耗时，而提示词微调通过巧妙地设计提示词，能够利用模型在预训练阶段学到的通用知识，即使只有少量数据，也能取得不错的效果。其次，由于提示词微调不需要对模型参数进行大规模调整，计算成本显著降低。这对于资源有限的中小企业或个人开发者来说，无疑是一个巨大的优势。此外，提示词微调更好地保留了模型在预训练阶段学到的通用知识，避免了“灾难性遗忘”问题，从而提升了模型在多任务上的表现。

作者：Deep Man
链接：https://zhuanlan.zhihu.com/p/25775384311
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。











#### **核心思想**

提示微调通过**修改输入结构（而非模型参数）**，将任务指令、示例或上下文嵌入输入文本中，引导模型利用预训练知识生成特定输出。以下是具体步骤分解：

------

#### **2. 输入改造流程**

假设原始输入为 `"你是谁"`，通过提示微调后的输入可能变为：

text

```text
[角色定义] 你是一个医疗助手，需用专业术语回答用户问题。
[示例] 
用户问：“什么是高血压？” → 回答：“高血压（Hypertension）是指血液在血管中流动时对血管壁造成的压力持续高于正常值的病理状态。”
[当前问题] 用户问：“你是谁” → 回答：
```

**分词与输入构造**：

1. 

   分词

   ：将改造后的文本转换为模型可理解的token序列。

   python

   ```python
   tokens = tokenizer.encode(
       "你是一个医疗助手...（完整提示）", 
       return_tensors="pt"
   )  # 例如：[101, 2345, 3052, ..., 102]
   ```

2. 

   输入格式

   ：实际输入模型的文本结构为：

   ```
   <角色定义> + <示例> + <当前问题> + <回答引导符>
   ```

------

#### **3. 微调策略分类**

##### **(1) 硬提示（Hard Prompt）**

- 

  手动设计模板

  ：直接修改输入文本格式。

  python

  ```python
  def hard_prompt(question):
      return f"""
      你是一名医生，请用医学术语回答。
      示例：
      问：什么是糖尿病？
      答：糖尿病（Diabetes Mellitus）是一种以高血糖为特征的代谢性疾病...
      问：{question}
      答："""
  
  input_text = hard_prompt("你是谁")
  ```

- **输出控制**：模型会基于角色定义和示例生成专业回答，而非通用回复。

##### **(2) 软提示（Soft Prompt）**

- 

  可学习提示向量

  ：在输入前添加可训练的连续向量（无需人工设计文本）。

  python

  ```python
  class SoftPrompt(nn.Module):
      def __init__(self, prompt_length=5, hidden_size=768):
          super().__init__()
          self.prompts = nn.Parameter(torch.randn(prompt_length, hidden_size))
      
      def forward(self, input_embeds):
          # 拼接可学习提示与原始输入
          return torch.cat([self.prompts, input_embeds], dim=1)
  
  # 示例：输入"你是谁"的嵌入 + 可学习提示
  input_ids = tokenizer("你是谁", return_tensors="pt").input_ids
  input_embeds = model.get_input_embeddings()(input_ids)
  soft_prompt_embeds = SoftPrompt()(input_embeds)
  ```

------

#### **4. 训练过程（以软提示为例）**

1. 

   冻结主模型

   ：保持预训练参数不变，仅训练提示向量。

   python

   ```python
   for param in model.parameters():
       param.requires_grad = False  # 冻结主模型
   prompt_parameters = [soft_prompt.prompts]  # 仅训练提示
   optimizer = Adam(prompt_parameters, lr=1e-3)
   ```

2. 

   前向传播

   ：

   python

   ```python
   outputs = model(inputs_embeds=soft_prompt_embeds)
   loss = loss_fn(outputs.logits, target_ids)
   ```

3. 

   反向传播

   ：仅更新提示向量。

   python

   ```python
   loss.backward()
   optimizer.step()
   ```

------

#### **5. 输入输出对比**

| **输入类型** |      原始输入      |          提示微调后的输入           |             模型输出示例              |
| :----------: | :----------------: | :---------------------------------: | :-----------------------------------: |
|    无提示    |      "你是谁"      |              "你是谁"               |   "我是一个AI助手，由XX公司开发..."   |
|    硬提示    | 见上文改造后的文本 |     包含角色、示例的结构化文本      | "我是医疗AI助手，用于提供疾病知识..." |
|    软提示    |      "你是谁"      | 原始文本 + 学习到的医疗领域提示向量 |  "我是基于循证医学的辅助诊断系统..."  |

------

### **关键总结**

1. **输入改造**：通过**结构化文本（硬提示）**或**可训练向量（软提示）**增强输入。
2. **训练目标**：让模型在特定上下文（如医疗场景）下生成专业回答。
3. **效率优势**：软提示仅需训练0.1%-1%的参数，即可适配新任务。

通过这种方式，原本通用的模型（如GPT-3）无需修改参数，即可被引导到垂直领域（如医疗、法律）的输出模式。





吴恩达在演讲中把智能体详细的分成了四类，分别是[Reflection](https://zhida.zhihu.com/search?content_id=708898105&content_type=Answer&match_order=1&q=Reflection&zhida_source=entity)、Tooluse、planning、multi- agent collaboration

![image-20250308161614004](/Users/moon/Library/Application Support/typora-user-images/image-20250308161614004.png)

如果用大语言模型塑造了一个“程序员”，你让他写个代码，它给你直接输出了答案，肯定不是最满意的，人类就要不断告诉他哪里需要修改。比如第几行有错误，怎么调整会更好。

![image-20250308161645969](/Users/moon/Library/Application Support/typora-user-images/image-20250308161645969.png)

如果你再新建一个“审查员”角色的大模型，用它来检查代码是否正确，并指出不足之处。根据“审查员”模型的反馈，“程序员”再次进行改进代码。反复循环这样的操作，直到结果让人满意为止。

![image-20250308161658646](/Users/moon/Library/Application Support/typora-user-images/image-20250308161658646.png)



作者：一枚卓子
链接：https://www.zhihu.com/question/661759314/answer/78912034125
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



**三、[Tool use](https://zhida.zhihu.com/search?content_id=708898105&content_type=Answer&match_order=1&q=Tool+use&zhida_source=entity) 工具调用**

通俗来讲，就像让我们人类算一个“12345 × 67890是多少？”咱也算不准，但我们拿个计算器，一下子就能得出准确结论。工具调用就是大语言模型会自己使用计算器。

在实际应用中，它会先**识别需求**：模型意识到它无法直接回答某个问题，需要借助工具。

再根据任务类型，判断要调用哪个工具，工具可以是计算器、知识库查询、数据库、搜索引擎，甚至是另一个模型。用工具完成任务后，将结果转化为人类易于理解的形式输出。

当大语言模型学会调用工具之后，有几个好处

1. **突破模型能力限制**：

语言模型擅长语言理解，但可能在计算、实时信息查询、专业领域数据处理等方面能力不足。工具使用可以弥补这些缺陷。就像人类一样，有人擅长文科，有人擅长理科，但是要是给人们一个计算器，谁都能算出来了。

2. **提升准确性和效率**：

比如在回答需要计算或实时查询的问题时，工具能提供精准答案，而不只是基于训练数据进行推测。你可以理解为大语言模型是一个人，塞给它一个工具，它就更准。

3. **扩展模型功能**：

这种能力将语言模型从“单一的大脑”扩展为一个“多功能助手”。，如编程调试、数据分析、内容生成等。

**ChatGPT添加插件的功能：如果你购买了ChatGPT Plus版，你可以来到插件商店里去选择插件帮助你完成更复杂的问题。**

speechki：文本转语音的插件，coupert：找优惠券和促销码，edx：找某个领域的优质课程， one word domains： 检查域名是否可用。

角色专业化是指大语言模型会提前设定好每个角色是干嘛的，比如他会告诉CEO，你是CEO你负责做决定。告诉CTO你负责系统设计。

记忆流保存了，之前对话的全部信息，让智能体不要忘记之前的沟通，做出正确的决策。

自我反思：是指两个人没有达成共识之前， 进行自我反思。最后达成共识。

我当时研究了这个虚拟公司以后，仿佛看到了未来AI的样子，每个人都可以是“老板”，你的手下会有一帮AI员工帮你完成复杂高难度的工作。

之所以我们现在感知不强烈，是因为这些模型都停留在代码阶段，并没有被开发成小白也能搞懂的应用。

作者：一枚卓子
链接：https://www.zhihu.com/question/661759314/answer/78912034125
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

![image-20250308161836818](/Users/moon/Library/Application Support/typora-user-images/image-20250308161836818.png)



Google : attetion is all you need



OpenAI:  规模就是一切



deepseek：强化学习就足够了



<img src="/Users/moon/Library/Application Support/typora-user-images/image-20250308180554346.png" alt="image-20250308180554346" style="zoom:50%;" />